                                                                                                                                                                                                                                                                
  GitHub Actions 실행 방법                                                                                                                                                                                                                                      
                                                                                                                                                                                                                                                                
  commit/push 없이도 실행 가능합니다. workflow_dispatch 트리거가 설정되어 있어서:                                                                                                                                                                               
                                                                                                                                                                                                                                                                
  1. GitHub repo → Actions 탭                                                                                                                                                                                                                                   
  2. 왼쪽에서 "Finance Pipeline" 선택                                                                                                                                                                                                                           
  3. "Run workflow" 버튼 클릭                                                                                                                                                                                                                                   
  4. 옵션 선택:                                                                                                                                                                                                                                                 
    - crawl_only: true면 검색/랭킹 스킵하고 DB의 pending 항목만 크롤링                                                                                                                                                                                          
    - skip_crawl: true면 크롤링 스킵 (테스트용)                                                                                                                                                                                                                 
                                                                                                                                                                                                                                                                
  ---                                                                                                                                                                                                                                                           
  파이프라인 흐름도                                                                                                                                                                                                                                             
                                                                                                                                                                                                                                                                
  ┌─────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                       
  │  Job 1: ingest-search (스킵 if crawl_only=true)                      │                                                                                                                                                                                      
  ├─────────────────────────────────────────────────────────────────────┤                                                                                                                                                                                       
  │  1. WSJ RSS Ingest     → wsj_items 테이블에 새 기사 저장              │                                                                                                                                                                                     
  │  2. Export to JSONL    → searched=false 항목 추출                    │                                                                                                                                                                                      
  │  3. Google News Search → 각 WSJ 기사의 백업 소스 검색                 │                                                                                                                                                                                     
  │                                                                      │                                                                                                                                                                                      
  │  Output: wsj_items.jsonl, wsj_google_news_results.jsonl             │                                                                                                                                                                                       
  └─────────────────────────────────────────────────────────────────────┘                                                                                                                                                                                       
                                      ↓                                                                                                                                                                                                                         
  ┌─────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                       
  │  Job 2: rank-resolve (스킵 if crawl_only=true)                       │                                                                                                                                                                                      
  ├─────────────────────────────────────────────────────────────────────┤                                                                                                                                                                                       
  │  4. Embedding Ranking  → WSJ 제목과 백업 기사 유사도 계산             │                                                                                                                                                                                     
  │  5. Resolve URLs       → Google News URL → 실제 URL 변환            │                                                                                                                                                                                       
  │     + Save to DB       → wsj_crawl_results 테이블에 저장             │                                                                                                                                                                                      
  │  6. Mark as searched   → wsj_items.searched = true                  │                                                                                                                                                                                       
  │                                                                      │                                                                                                                                                                                      
  │  Output: wsj_ranked_results.jsonl                                   │                                                                                                                                                                                       
  └─────────────────────────────────────────────────────────────────────┘                                                                                                                                                                                       
                                      ↓                                                                                                                                                                                                                         
  ┌─────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                       
  │  Job 3: crawl (또는 crawl-from-db if crawl_only=true)               │                                                                                                                                                                                       
  ├─────────────────────────────────────────────────────────────────────┤                                                                                                                                                                                       
  │  7. Crawl Articles (하이브리드 방식):                                 │                                                                                                                                                                                     
  │                                                                      │                                                                                                                                                                                      
  │     URL 하나씩 처리:                                                  │                                                                                                                                                                                     
  │     ┌─────────────────────────────────────────────────────────┐     │                                                                                                                                                                                       
  │     │ 1. newspaper4k 시도 (빠른 HTTP + 메타데이터)              │     │                                                                                                                                                                                     
  │     │    - blocked_domains면 스킵                              │     │                                                                                                                                                                                      
  │     │    - 성공시: authors, publish_date, top_image 추출       │     │                                                                                                                                                                                      
  │     │                                                          │     │                                                                                                                                                                                      
  │     │ 2. 실패시 → crawl4ai 브라우저 크롤링                      │     │                                                                                                                                                                                     
  │     │    - trafilatura로 콘텐츠 추출                           │     │                                                                                                                                                                                      
  │     │                                                          │     │                                                                                                                                                                                      
  │     │ 3. 품질 체크:                                            │     │                                                                                                                                                                                      
  │     │    - garbage 체크 (paywall, CSS/JS)                      │     │                                                                                                                                                                                      
  │     │    - embedding relevance 체크 (< 0.25 = low)             │     │                                                                                                                                                                                      
  │     │    - LLM relevance 체크 (same_event, score)              │     │                                                                                                                                                                                      
  │     │                                                          │     │                                                                                                                                                                                      
  │     │ 4. 결과에 따라:                                          │     │                                                                                                                                                                                      
  │     │    - success + ok → 다음 WSJ로 이동                      │     │                                                                                                                                                                                      
  │     │    - success + low → 다음 백업 시도                      │     │                                                                                                                                                                                      
  │     │    - garbage/failed → 다음 백업 시도                     │     │                                                                                                                                                                                      
  │     └─────────────────────────────────────────────────────────┘     │                                                                                                                                                                                       
  │                                                                      │                                                                                                                                                                                      
  │  즉시 DB 저장: crawl_status, content, top_image, relevance 등       │                                                                                                                                                                                       
  └─────────────────────────────────────────────────────────────────────┘                                                                                                                                                                                       
                                      ↓                                                                                                                                                                                                                         
  ┌─────────────────────────────────────────────────────────────────────┐                                                                                                                                                                                       
  │  Job 4: save-results                                                 │                                                                                                                                                                                      
  ├─────────────────────────────────────────────────────────────────────┤                                                                                                                                                                                       
  │  8. Mark processed     → success + ok인 WSJ items processed=true    │
  │  9. Update domain status → 도메인별 success_rate 계산               │
  └─────────────────────────────────────────────────────────────────────┘

---

## Session 2: Task Documentation Consolidation

### What was done
- Audited actual codebase vs task documentation
- Found two parallel tracks:
  - **Track A (ACTIVE)**: Python pipeline in `scripts/` - fully working
  - **Track B (ABANDONED)**: TypeScript library in `src/lib/finance/` - partial, unused

### Changes made
1. **Consolidated task file**: Updated `docs/workflow/3-tasks/2-tasks-finance-tts-briefing.md`
   - Documents actual Python pipeline implementation
   - Lists all 9 scripts with status
   - Shows 4 database tables
   - Marks Phase 1 (data collection) as complete
   - Defines Phase 2 (clustering/briefing) and Phase 3 (TTS/frontend) as remaining

2. **Archived old task files**:
   - `2.1-tasks-pipeline-fixes.archived.md` (all tasks were completed)
   - `2.3-task-llm-relevance-check.archived.md` (implementation done)

3. **Created branch**: `feature/finance-tts-briefing-2`

### Latest pipeline run
- Run ID: 21453378026
- Status: All 4 jobs passed
- Duration: ~1h41m total

### Next steps
- Phase 2: Event Clustering & Briefing Generation (Tasks 8-10)
- Phase 3: TTS Integration & Frontend (Tasks 11-12)      