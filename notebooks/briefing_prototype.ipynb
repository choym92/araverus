{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance Briefing Generator\n",
    "B-Gemini (full content) + Chirp 3 HD TTS (Alnilam voice)\n",
    "\n",
    "See: `docs/workflow/2-prds/3-prd-finance-briefing-v1.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected: Supabase, Gemini, Google Cloud TTS\n"
     ]
    }
   ],
   "source": [
    "import os, time, json, re, wave\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.cloud import texttospeech\n",
    "\n",
    "# Load env\n",
    "env_path = Path('../.env.local') if Path('../.env.local').exists() else Path('.env.local')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "sb = create_client(os.getenv('NEXT_PUBLIC_SUPABASE_URL'), os.getenv('SUPABASE_SERVICE_ROLE_KEY'))\n",
    "gemini_client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "chirp_client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "print('Connected: Supabase, Gemini, Google Cloud TTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Today's Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in window (48h): 70 (filtered 0 previously briefed)\n",
      "  BUSINESS_MARKETS: 38\n",
      "  WORLD: 14\n",
      "  ECONOMY: 8\n",
      "  TECH: 5\n",
      "  POLITICS: 5\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "\n",
    "# 48h lookback window + briefed filter (curated articles excluded)\n",
    "cutoff = today - timedelta(hours=48)\n",
    "\n",
    "items = sb.table('wsj_items') \\\n",
    "    .select('id,title,description,feed_name,published_at,link,briefed') \\\n",
    "    .gte('published_at', cutoff.strftime('%Y-%m-%dT%H:%M:%S')) \\\n",
    "    .order('published_at', desc=True) \\\n",
    "    .execute()\n",
    "\n",
    "# Filter out articles already curated in previous briefings\n",
    "before_count = len(items.data)\n",
    "items.data = [i for i in items.data if not i.get('briefed')]\n",
    "\n",
    "print(f'Articles in window (48h): {len(items.data)} (filtered {before_count - len(items.data)} previously briefed)')\n",
    "cats = Counter(i['feed_name'] for i in items.data)\n",
    "for cat, count in cats.most_common():\n",
    "    print(f'  {cat}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #  Category             Published    Title\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1  BUSINESS_MARKETS     2026-02-17 01:00 Starboard to Push for Big Shake-Up of Tripadvisor’s Board\n",
      "  2  WORLD                2026-02-17 01:00 Britain’s Monarchy Can’t Escape the Shadow of the Epstein Scandal\n",
      "  3  BUSINESS_MARKETS     2026-02-17 00:33 Anderson Cooper to Leave CBS News’s ‘60 Minutes’\n",
      "  4  TECH                 2026-02-17 00:12 Irish Data Watchdog Opens Inquiry into X Over Grok AI Images\n",
      "  5  BUSINESS_MARKETS     2026-02-16 23:45 BHP Exploring Infrastructure Deals as It Chases $10 Billion Targe\n",
      "  6  BUSINESS_MARKETS     2026-02-16 22:39 Nancy Guthrie’s Family Cleared as Suspects in Disappearance\n",
      "  7  BUSINESS_MARKETS     2026-02-16 21:53 Thomas Pritzker, Named in Epstein Files, Retires as Hyatt Executi\n",
      "  8  WORLD                2026-02-16 21:36 The Canada School Shooting Touched Almost Everyone at a U.S.-Back\n",
      "  9  BUSINESS_MARKETS     2026-02-16 19:11 The 500-Year-Old Beretta Gun Dynasty Is Betting Big on the U.S.\n",
      " 10  BUSINESS_MARKETS     2026-02-16 18:28 Nasdaq Futures Fall Ahead of Busy Week\n",
      " 11  TECH                 2026-02-16 18:00 Yes, You Can Vibe-Code. Here’s How to Get Started.\n",
      " 12  POLITICS             2026-02-16 17:00 The Newest Old Tech in Warfare: Balloons\n",
      " 13  BUSINESS_MARKETS     2026-02-16 16:00 Smithfield Foods to Build New South Dakota Pork Plant\n",
      " 14  BUSINESS_MARKETS     2026-02-16 16:00 Marketplaces Are the Next Frontier in Publisher Deals With AI Com\n",
      " 15  TECH                 2026-02-16 15:00 With a Frugal AI Strategy, India Offers Blueprint for Developing \n",
      " 16  BUSINESS_MARKETS     2026-02-16 14:36 U.K. Regulator Weighs Rule Change to Attract Chinese Listings\n",
      " 17  ECONOMY              2026-02-16 13:55 Canada Factory Sales Inch Up\n",
      " 18  BUSINESS_MARKETS     2026-02-16 11:39 Basic Materials Roundup: Market Talk\n",
      " 19  BUSINESS_MARKETS     2026-02-16 11:29 Financial Services Roundup: Market Talk\n",
      " 20  BUSINESS_MARKETS     2026-02-16 10:30 We Asked What Makes You an Economic Optimist. Here’s What You Sai\n",
      " 21  ECONOMY              2026-02-16 10:30 Americans offer plenty of reasons for pessimism about the economy\n",
      " 22  BUSINESS_MARKETS     2026-02-16 10:23 ECB’s Move to Boost Euro’s Global Role Looks Positive For Currenc\n",
      " 23  ECONOMY              2026-02-16 10:22 Eurozone Industrial Output Declines\n",
      " 24  BUSINESS_MARKETS     2026-02-16 10:12 Hapag-Lloyd in Advanced Talks Over Potential Acquisition of Israe\n",
      " 25  ECONOMY              2026-02-16 10:03 Swiss Economy Swings to Growth\n",
      " 26  POLITICS             2026-02-16 10:00 So it turns out that Congress may have actually waived many of th\n",
      " 27  BUSINESS_MARKETS     2026-02-16 09:55 U.S. Futures Edge Up as Public Holidays Dim Trading\n",
      " 28  BUSINESS_MARKETS     2026-02-16 09:40 European Gas Prices Fall As Supply Holds Steady Despite Tight Sto\n",
      " 29  BUSINESS_MARKETS     2026-02-16 09:26 Gold Above $5,000 But Holiday-Thinned Trade Limits Gains\n",
      " 30  BUSINESS_MARKETS     2026-02-16 09:06 Oil Broadly Steady Ahead of U.S.-Iran Talks\n",
      " 31  BUSINESS_MARKETS     2026-02-16 08:35 Eurozone Bond Yields Drift Lower, Await Fresh Drivers\n",
      " 32  BUSINESS_MARKETS     2026-02-16 06:28 BlueScope Relegates Plans for U.S. Midstream Growth\n",
      " 33  ECONOMY              2026-02-16 06:14 Japan’s Narrow Growth Tests Fiscal, Monetary Policy Paths\n",
      " 34  ECONOMY              2026-02-16 05:50 January’s Gains Endure as High Supply Tempers February U.K. House\n",
      " 35  WORLD                2026-02-16 04:00 Millions Face Starvation in Congo. Their New Rulers Are to Blame.\n",
      " 36  WORLD                2026-02-16 03:00 A Defector Explains the Remote-Work Scam Helping North Korea Pay \n",
      " 37  BUSINESS_MARKETS     2026-02-16 03:00 The Break Is Over. Companies Are Jacking Up Prices Again.\n",
      " 38  WORLD                2026-02-16 02:38 Canada to Prioritize Domestic Firms in Defense-Spending Plan Amid\n",
      " 39  BUSINESS_MARKETS     2026-02-16 02:00 In a Chaotic Market, Investors Learn How to Cope With Surprises\n",
      " 40  BUSINESS_MARKETS     2026-02-16 02:00 Companies Are Replacing CEOs in Record Numbers—and They’re Gettin\n",
      " 41  POLITICS             2026-02-16 00:22 The U.S. military airlifted on Sunday a miniature nuclear reactor\n",
      " 42  BUSINESS_MARKETS     2026-02-15 23:57 Qube Agrees to Macquarie-Led Consortium Takeover Valuing It at $6\n",
      " 43  WORLD                2026-02-15 19:46 U.S. and Europe, No Longer Kindred Souls, Enter a Marriage of Con\n",
      " 44  WORLD                2026-02-15 17:09 Doctors Without Borders Says Gunmen Are Using a Gaza Hospital, Po\n",
      " 45  BUSINESS_MARKETS     2026-02-15 17:00 How Blockbuster Films and Bingeworthy Streaming Hits Slipped Into\n",
      " 46  TECH                 2026-02-15 15:59 What’s Left For Humans?\n",
      " 47  POLITICS             2026-02-15 13:39 While the main focus of the Munich Security Conference was on the\n",
      " 48  ECONOMY              2026-02-15 13:00 Easier access to home loans and modular construction are among th\n",
      " 49  TECH                 2026-02-15 10:47 TikTok’s Chinese Parent Has an App to Replace Hollywood\n",
      " 50  BUSINESS_MARKETS     2026-02-15 10:30 The Private Manhattan Club With a Jeffrey Epstein Problem\n",
      " 51  BUSINESS_MARKETS     2026-02-15 10:30 The Ivies Are Having Second Thoughts About Investing in Private E\n",
      " 52  BUSINESS_MARKETS     2026-02-15 10:30 Bezos vs. Musk: The New Billionaire Battle for the Moon\n",
      " 53  WORLD                2026-02-15 04:00 China Watchers Are Trying to Spot the Next Target of Xi’s Purges\n",
      " 54  WORLD                2026-02-15 03:00 On the Ground With Crews Battling to Keep the Lights On in Ukrain\n",
      " 55  ECONOMY              2026-02-15 02:00 Inflation is easing, jobs are holding up, and growth is solid. Bu\n",
      " 56  BUSINESS_MARKETS     2026-02-15 02:00 Farmers Are Aging. Their Kids Don’t Want to Be in the Family Busi\n",
      " 57  BUSINESS_MARKETS     2026-02-15 01:00 Gen Z, Locked Out of Home Buying, Puts Its Money in the Market\n",
      " 58  WORLD                2026-02-14 22:43 Teen Suspect in Canada Shooting Had Turbulent Life Marred by ‘Nom\n",
      " 59  BUSINESS_MARKETS     2026-02-14 19:26 How Kathy Ruemmler and Goldman Sachs Finally Reached Their Breaki\n",
      " 60  BUSINESS_MARKETS     2026-02-14 17:00 Phonographs, Player Pianos and Betamax: The Inventions That Trans\n",
      " 61  WORLD                2026-02-14 17:00 Canada Has a Secessionist Movement on Its Hands. Its Supporters T\n",
      " 62  WORLD                2026-02-14 16:22 Navalny Killed by Poison Frog Toxin, European Governments Say\n",
      " 63  BUSINESS_MARKETS     2026-02-14 11:00 News quiz for Feb. 14, 2026\n",
      " 64  WORLD                2026-02-14 09:45 Rubio Seeks to Reassure European Allies in Munich Speech\n",
      " 65  BUSINESS_MARKETS     2026-02-14 04:00 China Deploys a ‘National Team’ of Investors to Keep AI Stock Boo\n",
      " 66  WORLD                2026-02-14 04:00 Saudi Youth Couldn’t Date Openly a Decade Ago. Now Tinder Is Boom\n",
      " 67  BUSINESS_MARKETS     2026-02-14 03:45 Casey Wasserman Is Putting His Talent Agency Up for Sale After Ep\n",
      " 68  POLITICS             2026-02-14 02:00 As midterm elections approach, some rank-and-file House Republica\n",
      " 69  BUSINESS_MARKETS     2026-02-14 02:00 America Fell Out of Love With the Sedan. Detroit Wants to Bring I\n",
      " 70  BUSINESS_MARKETS     2026-02-14 01:00 A Pilot’s Parents Work to Clear His Name After the Deadliest Cras\n"
     ]
    }
   ],
   "source": [
    "# Validate: show all article titles with category and time\n",
    "print(f'{\"#\":>3}  {\"Category\":<20} {\"Published\":<12} Title')\n",
    "print('-' * 100)\n",
    "for i, item in enumerate(items.data, 1):\n",
    "    cat = item['feed_name']\n",
    "    pub = item['published_at'][:16].replace('T', ' ')\n",
    "    title = item['title'][:65]\n",
    "    print(f'{i:>3}  {cat:<20} {pub:<12} {title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join with Crawl Results + LLM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with crawl results: 46\n",
      "Articles with LLM analysis: 40\n"
     ]
    }
   ],
   "source": [
    "item_ids = [i['id'] for i in items.data]\n",
    "\n",
    "crawl_map = {}\n",
    "for i in range(0, len(item_ids), 100):\n",
    "    batch = item_ids[i:i+100]\n",
    "    crawls = sb.table('wsj_crawl_results') \\\n",
    "        .select('id,wsj_item_id,content,crawl_status,relevance_score,relevance_flag,llm_same_event,llm_score,resolved_domain') \\\n",
    "        .in_('wsj_item_id', batch) \\\n",
    "        .eq('crawl_status', 'success') \\\n",
    "        .execute()\n",
    "    for c in crawls.data:\n",
    "        wid = c['wsj_item_id']\n",
    "        if wid not in crawl_map or (c.get('llm_score') or 0) > (crawl_map[wid].get('llm_score') or 0):\n",
    "            crawl_map[wid] = c\n",
    "\n",
    "quality_crawl_ids = [c['id'] for c in crawl_map.values()]\n",
    "llm_map = {}\n",
    "for i in range(0, len(quality_crawl_ids), 100):\n",
    "    batch = quality_crawl_ids[i:i+100]\n",
    "    analyses = sb.table('wsj_llm_analysis') \\\n",
    "        .select('crawl_result_id,summary,key_entities,key_numbers,event_type,sentiment') \\\n",
    "        .in_('crawl_result_id', batch) \\\n",
    "        .execute()\n",
    "    for a in analyses.data:\n",
    "        llm_map[a['crawl_result_id']] = a\n",
    "\n",
    "print(f'Articles with crawl results: {len(crawl_map)}')\n",
    "print(f'Articles with LLM analysis: {len(llm_map)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #  Crawl   Rel  LLM  Same Domain                    Title\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "  1   MISS     -    -     -                           Starboard to Push for Big Shake-Up of Tripadv\n",
      "  2   MISS     -    -     -                           Britain’s Monarchy Can’t Escape the Shadow of\n",
      "  3   MISS     -    -     -                           Anderson Cooper to Leave CBS News’s ‘60 Minut\n",
      "  4   MISS     -    -     -                           Irish Data Watchdog Opens Inquiry into X Over\n",
      "  5   MISS     -    -     -                           BHP Exploring Infrastructure Deals as It Chas\n",
      "  6   MISS     -    -     -                           Nancy Guthrie’s Family Cleared as Suspects in\n",
      "  7   MISS     -    -     -                           Thomas Pritzker, Named in Epstein Files, Reti\n",
      "  8   MISS     -    -     -                           The Canada School Shooting Touched Almost Eve\n",
      "  9   MISS     -    -     -                           The 500-Year-Old Beretta Gun Dynasty Is Betti\n",
      " 10   MISS     -    -     -                           Nasdaq Futures Fall Ahead of Busy Week\n",
      " 11   MISS     -    -     -                           Yes, You Can Vibe-Code. Here’s How to Get Sta\n",
      " 12   MISS     -    -     -                           The Newest Old Tech in Warfare: Balloons\n",
      " 13   MISS     -    -     -                           Smithfield Foods to Build New South Dakota Po\n",
      " 14   MISS     -    -     -                           Marketplaces Are the Next Frontier in Publish\n",
      " 15   MISS     -    -     -                           With a Frugal AI Strategy, India Offers Bluep\n",
      " 16   MISS     -    -     -                           U.K. Regulator Weighs Rule Change to Attract \n",
      " 17   MISS     -    -     -                           Canada Factory Sales Inch Up\n",
      " 18     OK  0.18  0.0     N finance.yahoo.com         Basic Materials Roundup: Market Talk\n",
      " 19     OK  0.33  7.0     Y finance.yahoo.com         Financial Services Roundup: Market Talk\n",
      " 20     OK  0.33  2.0     N augustachronicle.com      We Asked What Makes You an Economic Optimist.\n",
      " 21     OK  0.19  0.0     N ca.investing.com          Americans offer plenty of reasons for pessimi\n",
      " 22     OK  0.69  8.0     Y businessday.co.za         ECB’s Move to Boost Euro’s Global Role Looks \n",
      " 23     OK  0.72  9.0     Y tradingeconomics.com      Eurozone Industrial Output Declines\n",
      " 24     OK  0.58  9.0     Y logisticsinsider.in       Hapag-Lloyd in Advanced Talks Over Potential \n",
      " 25     OK  0.74  9.0     Y marketscreener.com        Swiss Economy Swings to Growth\n",
      " 26   MISS     -    -     -                           So it turns out that Congress may have actual\n",
      " 27     OK  0.79  8.0     Y uk.marketscreener.com     U.S. Futures Edge Up as Public Holidays Dim T\n",
      " 28     OK  0.65  8.0     Y binance.com               European Gas Prices Fall As Supply Holds Stea\n",
      " 29     OK  0.72  8.0     Y businessday.co.za         Gold Above $5,000 But Holiday-Thinned Trade L\n",
      " 30     OK  0.54  8.0     Y businessday.co.za         Oil Broadly Steady Ahead of U.S.-Iran Talks\n",
      " 31     OK  0.48  3.0     N finimize.com              Eurozone Bond Yields Drift Lower, Await Fresh\n",
      " 32   MISS     -    -     -                           BlueScope Relegates Plans for U.S. Midstream \n",
      " 33     OK  0.64  7.0     Y nai500.com                Japan’s Narrow Growth Tests Fiscal, Monetary \n",
      " 34     OK  0.03  0.0     N fastbull.com              January’s Gains Endure as High Supply Tempers\n",
      " 35     OK  0.61  8.0     Y livemint.com              Millions Face Starvation in Congo. Their New \n",
      " 36     OK  0.08  0.0     N marketscreener.com        A Defector Explains the Remote-Work Scam Help\n",
      " 37     OK  0.52  7.0     Y floridatoday.com          The Break Is Over. Companies Are Jacking Up P\n",
      " 38     OK  0.48  8.0     Y ctvnews.ca                Canada to Prioritize Domestic Firms in Defens\n",
      " 39     OK  0.59  8.0     Y uk.marketscreener.com     In a Chaotic Market, Investors Learn How to C\n",
      " 40   MISS     -    -     -                           Companies Are Replacing CEOs in Record Number\n",
      " 41     OK  0.69  9.0     Y thehawk.in                The U.S. military airlifted on Sunday a minia\n",
      " 42     OK  0.84  8.0     Y marketscreener.com        Qube Agrees to Macquarie-Led Consortium Takeo\n",
      " 43     OK  0.62  8.0     Y livemint.com              U.S. and Europe, No Longer Kindred Souls, Ent\n",
      " 44     OK  0.76  7.0     Y timesofisrael.com         Doctors Without Borders Says Gunmen Are Using\n",
      " 45     OK  0.23  0.0     N swingtradebot.com         How Blockbuster Films and Bingeworthy Streami\n",
      " 46     OK  0.31  5.0     N simplilearn.com           What’s Left For Humans?\n",
      " 47     OK  0.40  5.0     Y bbc.co.uk                 While the main focus of the Munich Security C\n",
      " 48     OK  0.34  0.0     N wacities.org              Easier access to home loans and modular const\n",
      " 49     OK  0.57  7.0     Y futurism.com              TikTok’s Chinese Parent Has an App to Replace\n",
      " 50     OK  0.35  5.0     N newstribune.com           The Private Manhattan Club With a Jeffrey Eps\n",
      " 51   MISS     -    -     -                           The Ivies Are Having Second Thoughts About In\n",
      " 52     OK  0.80  8.0     Y itiger.com                Bezos vs. Musk: The New Billionaire Battle fo\n",
      " 53     OK  0.36  8.0     Y livemint.com              China Watchers Are Trying to Spot the Next Ta\n",
      " 54     OK  0.53  9.0     Y livemint.com              On the Ground With Crews Battling to Keep the\n",
      " 55     OK  0.48  8.0     Y livemint.com              Inflation is easing, jobs are holding up, and\n",
      " 56     OK  0.47  3.0     N wvia.org                  Farmers Are Aging. Their Kids Don’t Want to B\n",
      " 57     OK  0.27  0.0     N nasdaq.com                Gen Z, Locked Out of Home Buying, Puts Its Mo\n",
      " 58     OK  0.43  2.0     N yahoo.com                 Teen Suspect in Canada Shooting Had Turbulent\n",
      " 59     OK  0.61  8.0     Y cnn.com                   How Kathy Ruemmler and Goldman Sachs Finally \n",
      " 60     OK  0.24  0.0     N mdpi.com                  Phonographs, Player Pianos and Betamax: The I\n",
      " 61     OK  0.69  8.0     Y oilprice.com              Canada Has a Secessionist Movement on Its Han\n",
      " 62     OK  0.77  9.0     Y cnn.com                   Navalny Killed by Poison Frog Toxin, European\n",
      " 63   MISS     -    -     -                           News quiz for Feb. 14, 2026\n",
      " 64   MISS     -    -     -                           Rubio Seeks to Reassure European Allies in Mu\n",
      " 65     OK  0.51  0.0     N exportprac.com            China Deploys a ‘National Team’ of Investors \n",
      " 66   MISS     -    -     -                           Saudi Youth Couldn’t Date Openly a Decade Ago\n",
      " 67     OK  0.60  6.0     Y ca.news.yahoo.com         Casey Wasserman Is Putting His Talent Agency \n",
      " 68     OK  0.29  3.0     N washingtonpost.com        As midterm elections approach, some rank-and-\n",
      " 69     OK  0.52  7.0     Y sahmcapital.com           America Fell Out of Love With the Sedan. Detr\n",
      " 70     OK  0.40  8.0     Y livemint.com              A Pilot’s Parents Work to Clear His Name Afte\n",
      "\n",
      "--- Missing crawl (24): ---\n",
      "  - Starboard to Push for Big Shake-Up of Tripadvisor’s Board\n",
      "  - Britain’s Monarchy Can’t Escape the Shadow of the Epstein Scandal\n",
      "  - Anderson Cooper to Leave CBS News’s ‘60 Minutes’\n",
      "  - Irish Data Watchdog Opens Inquiry into X Over Grok AI Images\n",
      "  - BHP Exploring Infrastructure Deals as It Chases $10 Billion Target\n",
      "  - Nancy Guthrie’s Family Cleared as Suspects in Disappearance\n",
      "  - Thomas Pritzker, Named in Epstein Files, Retires as Hyatt Executive Chairman\n",
      "  - The Canada School Shooting Touched Almost Everyone at a U.S.-Backed Coal Company\n",
      "  - The 500-Year-Old Beretta Gun Dynasty Is Betting Big on the U.S.\n",
      "  - Nasdaq Futures Fall Ahead of Busy Week\n",
      "  - Yes, You Can Vibe-Code. Here’s How to Get Started.\n",
      "  - The Newest Old Tech in Warfare: Balloons\n",
      "  - Smithfield Foods to Build New South Dakota Pork Plant\n",
      "  - Marketplaces Are the Next Frontier in Publisher Deals With AI Companies\n",
      "  - With a Frugal AI Strategy, India Offers Blueprint for Developing World\n",
      "  - U.K. Regulator Weighs Rule Change to Attract Chinese Listings\n",
      "  - Canada Factory Sales Inch Up\n",
      "  - So it turns out that Congress may have actually waived many of the tax code’s filing and payment deadlines for three and a half years during the pandemic. The fallout is just starting.\n",
      "  - BlueScope Relegates Plans for U.S. Midstream Growth\n",
      "  - Companies Are Replacing CEOs in Record Numbers—and They’re Getting Younger\n",
      "  - The Ivies Are Having Second Thoughts About Investing in Private Equity\n",
      "  - News quiz for Feb. 14, 2026\n",
      "  - Rubio Seeks to Reassure European Allies in Munich Speech\n",
      "  - Saudi Youth Couldn’t Date Openly a Decade Ago. Now Tinder Is Booming.\n"
     ]
    }
   ],
   "source": [
    "# Validate: crawl + LLM join results per article\n",
    "print(f'{\"#\":>3}  {\"Crawl\":>5} {\"Rel\":>5} {\"LLM\":>4} {\"Same\":>5} {\"Domain\":<25} Title')\n",
    "print('-' * 110)\n",
    "for i, item in enumerate(items.data, 1):\n",
    "    wid = item['id']\n",
    "    crawl = crawl_map.get(wid)\n",
    "    has_llm = crawl and crawl['id'] in llm_map\n",
    "    if crawl:\n",
    "        rel = f'{crawl.get(\"relevance_score\") or 0:.2f}'\n",
    "        llm_s = f'{crawl.get(\"llm_score\") or 0:.1f}'\n",
    "        same = 'Y' if crawl.get('llm_same_event') else 'N'\n",
    "        domain = (crawl.get('resolved_domain') or '')[:25]\n",
    "    else:\n",
    "        rel = llm_s = same = '-'\n",
    "        domain = ''\n",
    "    crawl_flag = 'OK' if crawl else 'MISS'\n",
    "    llm_flag = '+' if has_llm else ''\n",
    "    title = item['title'][:45]\n",
    "    print(f'{i:>3}  {crawl_flag:>5} {rel:>5} {llm_s:>4} {same:>5} {domain:<25} {title}')\n",
    "\n",
    "missing = [item['title'] for item in items.data if item['id'] not in crawl_map]\n",
    "print(f'\\n--- Missing crawl ({len(missing)}): ---')\n",
    "for t in missing:\n",
    "    print(f'  - {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Curation — Pick Top Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curating 70 articles... Pro(1)\n",
      "Raw: [4, 10, 12, 14, 15, 22, 23, 24, 33, 37, 42, 46, 49, 55, 65]\n",
      "8.1s — picked 15 articles\n",
      "Curation model: Pro (gemini-2.5-pro)\n",
      "Thinking: 774 / 1,024 (76% used)\n",
      "\n",
      "Curated articles:\n",
      "    4. [TECH                ] Irish Data Watchdog Opens Inquiry into X Over Grok AI Images\n",
      "   10. [BUSINESS_MARKETS    ] Nasdaq Futures Fall Ahead of Busy Week\n",
      "   12. [POLITICS            ] The Newest Old Tech in Warfare: Balloons\n",
      "   14. [BUSINESS_MARKETS    ] Marketplaces Are the Next Frontier in Publisher Deals With AI Companie\n",
      "   15. [TECH                ] With a Frugal AI Strategy, India Offers Blueprint for Developing World\n",
      "   22. [BUSINESS_MARKETS    ] ECB’s Move to Boost Euro’s Global Role Looks Positive For Currency\n",
      "   23. [ECONOMY             ] Eurozone Industrial Output Declines\n",
      "   24. [BUSINESS_MARKETS    ] Hapag-Lloyd in Advanced Talks Over Potential Acquisition of Israeli Ri\n",
      "   33. [ECONOMY             ] Japan’s Narrow Growth Tests Fiscal, Monetary Policy Paths\n",
      "   37. [BUSINESS_MARKETS    ] The Break Is Over. Companies Are Jacking Up Prices Again.\n",
      "   42. [BUSINESS_MARKETS    ] Qube Agrees to Macquarie-Led Consortium Takeover Valuing It at $6.51 B\n",
      "   46. [TECH                ] What’s Left For Humans?\n",
      "   49. [TECH                ] TikTok’s Chinese Parent Has an App to Replace Hollywood\n",
      "   55. [ECONOMY             ] Inflation is easing, jobs are holding up, and growth is solid. But aft\n",
      "   65. [BUSINESS_MARKETS    ] China Deploys a ‘National Team’ of Investors to Keep AI Stock Boom in \n"
     ]
    }
   ],
   "source": [
    "# LLM curation: Pick top 10-15 high-impact articles\n",
    "# Strategy: try Pro (3 attempts), fallback to Flash if Pro keeps failing\n",
    "\n",
    "CURATION_PROMPT = \"\"\"You are a senior financial news editor. From the article list below, pick the 10-15 most important stories that deserve deep coverage in a daily briefing.\n",
    "\n",
    "Selection criteria (in priority order):\n",
    "1. Macroeconomic impact: interest rates, inflation, GDP, employment, central bank decisions\n",
    "2. AI/Tech major moves: big product launches, regulatory shifts, large deals, industry trends\n",
    "3. Market-wide impact: major M&A, significant earnings beats/misses, policy changes\n",
    "4. Geopolitical events with direct market implications\n",
    "\n",
    "Mandatory inclusion:\n",
    "- ALWAYS include ALL articles tagged [TECH] or related to AI/technology, unless they are purely lifestyle/opinion pieces with no market relevance.\n",
    "\n",
    "Exclusion:\n",
    "- SKIP executive personnel stories (CEO/CFO/lawyer hired, fired, stepped down, pay raises) unless the departure signals a major corporate crisis or strategic shift.\n",
    "- SKIP \"Roundup: Market Talk\" digest articles — they are low-value summaries.\n",
    "\n",
    "Rules:\n",
    "- If multiple articles cover the same event, pick only the one with the richest detail.\n",
    "- Return ONLY a JSON array of article numbers (1-indexed), nothing else.\n",
    "- No explanation, no text before or after. Just the array.\n",
    "- Example: [3, 7, 12, 15, 22, 28, 33, 41, 45, 50, 55]\n",
    "\"\"\"\n",
    "\n",
    "# Build article list for curation\n",
    "curation_lines = []\n",
    "for i, item in enumerate(items.data, 1):\n",
    "    wid = item['id']\n",
    "    crawl = crawl_map.get(wid)\n",
    "    llm = llm_map.get(crawl['id']) if crawl and crawl['id'] in llm_map else {}\n",
    "    entities = ', '.join(llm.get('key_entities', []))[:80]\n",
    "    line = f\"{i}. [{item['feed_name']}] {item['title']}\"\n",
    "    if item.get('description'):\n",
    "        line += f\" — {item['description'][:120]}\"\n",
    "    if entities:\n",
    "        line += f\" (Entities: {entities})\"\n",
    "    curation_lines.append(line)\n",
    "\n",
    "curation_input = CURATION_PROMPT + \"\\n\\n\" + \"\\n\".join(curation_lines)\n",
    "\n",
    "CURATION_THINKING_BUDGET = 1024\n",
    "\n",
    "def try_curation(model, config, label):\n",
    "    \"\"\"Try curation with given model. Returns raw text or None.\"\"\"\n",
    "    try:\n",
    "        resp = gemini_client.models.generate_content(\n",
    "            model=model, contents=curation_input, config=config,\n",
    "        )\n",
    "        # Try .text first\n",
    "        try:\n",
    "            if resp.text:\n",
    "                return resp.text, resp\n",
    "        except Exception:\n",
    "            pass\n",
    "        # Manual extraction from parts\n",
    "        for cand in (resp.candidates or []):\n",
    "            for part in (cand.content.parts if cand.content and cand.content.parts else []):\n",
    "                if hasattr(part, 'thought') and part.thought:\n",
    "                    continue\n",
    "                if hasattr(part, 'text') and part.text:\n",
    "                    return part.text, resp\n",
    "        print(f'\\n  {label}: empty response')\n",
    "        return None, resp\n",
    "    except Exception as e:\n",
    "        print(f'\\n  {label}: {e.__class__.__name__}: {e}')\n",
    "        return None, None\n",
    "\n",
    "print(f'Curating {len(items.data)} articles...', end='')\n",
    "start = time.time()\n",
    "\n",
    "raw = None\n",
    "resp = None\n",
    "\n",
    "# Try Pro up to 3 times\n",
    "for attempt in range(3):\n",
    "    print(f' Pro({attempt+1})', end='')\n",
    "    raw, resp = try_curation(\n",
    "        'gemini-2.5-pro',\n",
    "        types.GenerateContentConfig(\n",
    "            max_output_tokens=4096,\n",
    "            temperature=0.1,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=CURATION_THINKING_BUDGET),\n",
    "        ),\n",
    "        f'Pro attempt {attempt+1}',\n",
    "    )\n",
    "    if raw:\n",
    "        break\n",
    "    time.sleep(2)\n",
    "\n",
    "# Fallback to Flash\n",
    "if not raw:\n",
    "    print(' -> Flash fallback', end='')\n",
    "    raw, resp = try_curation(\n",
    "        'gemini-2.5-flash',\n",
    "        types.GenerateContentConfig(\n",
    "            max_output_tokens=1024,\n",
    "            temperature=0.0,\n",
    "        ),\n",
    "        'Flash',\n",
    "    )\n",
    "\n",
    "if not raw:\n",
    "    raise ValueError('Curation failed on both Pro and Flash')\n",
    "\n",
    "raw = raw.strip()\n",
    "print(f'\\nRaw: {raw}')\n",
    "\n",
    "# Parse JSON array\n",
    "cleaned = re.sub(r'```json\\s*', '', raw)\n",
    "cleaned = re.sub(r'```\\s*', '', cleaned).strip()\n",
    "match = re.search(r'\\[[\\d,\\s]+\\]', cleaned)\n",
    "if not match:\n",
    "    raise ValueError(f'Could not parse JSON array: {raw}')\n",
    "\n",
    "curated_indices = json.loads(match.group())\n",
    "curated_ids = set(items.data[i - 1]['id'] for i in curated_indices if 1 <= i <= len(items.data))\n",
    "\n",
    "elapsed = time.time() - start\n",
    "model_used = 'Pro' if 'pro' in (resp.model_version or '') else ('Flash' if resp else '?')\n",
    "\n",
    "# Save token usage for summary\n",
    "um = resp.usage_metadata\n",
    "curation_usage = {\n",
    "    'step': 'Curation',\n",
    "    'model': resp.model_version if resp else '?',\n",
    "    'thinking_budget': CURATION_THINKING_BUDGET,\n",
    "    'thinking_used': getattr(um, 'thinking_token_count', None) or getattr(um, 'thoughts_token_count', None) or 0,\n",
    "    'input_tokens': um.prompt_token_count if resp else 0,\n",
    "    'output_tokens': um.candidates_token_count if resp else 0,\n",
    "    'elapsed': elapsed,\n",
    "}\n",
    "\n",
    "print(f'{elapsed:.1f}s — picked {len(curated_ids)} articles')\n",
    "print(f'Curation model: {model_used} ({resp.model_version})')\n",
    "print(f'Thinking: {curation_usage[\"thinking_used\"]:,} / {CURATION_THINKING_BUDGET:,} ({curation_usage[\"thinking_used\"]/CURATION_THINKING_BUDGET*100:.0f}% used)')\n",
    "\n",
    "print(f'\\nCurated articles:')\n",
    "for i in sorted(curated_indices):\n",
    "    if 1 <= i <= len(items.data):\n",
    "        item = items.data[i - 1]\n",
    "        print(f'  {i:>3}. [{item[\"feed_name\"]:<20}] {item[\"title\"][:70]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter & Assemble Input (Full Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 70\n",
      "  Quality crawl: 30\n",
      "    Curated (full content): 8\n",
      "    Standard ([:800]):      22\n",
      "  Title+desc only: 40\n"
     ]
    }
   ],
   "source": [
    "RELEVANCE_THRESHOLD = 0.6\n",
    "\n",
    "articles = []\n",
    "quality_count = 0\n",
    "curated_full_count = 0\n",
    "title_only_count = 0\n",
    "\n",
    "for item in items.data:\n",
    "    wid = item['id']\n",
    "    crawl = crawl_map.get(wid)\n",
    "    is_curated = wid in curated_ids\n",
    "\n",
    "    has_quality = False\n",
    "    if crawl:\n",
    "        score = crawl.get('relevance_score') or 0\n",
    "        same_event = crawl.get('llm_same_event', False)\n",
    "        has_quality = score >= RELEVANCE_THRESHOLD or same_event\n",
    "\n",
    "    base = {\n",
    "        'id': wid,\n",
    "        'title': item['title'],\n",
    "        'description': item.get('description') or '',\n",
    "        'category': item['feed_name'],\n",
    "        'published_at': item.get('published_at', ''),\n",
    "        'has_quality_crawl': has_quality,\n",
    "        'is_curated': is_curated,\n",
    "    }\n",
    "\n",
    "    if has_quality:\n",
    "        quality_count += 1\n",
    "        llm = llm_map.get(crawl['id'], {})\n",
    "        # Curated articles get full content, others get [:800]\n",
    "        content = crawl.get('content') or ''\n",
    "        if is_curated:\n",
    "            curated_full_count += 1\n",
    "        else:\n",
    "            content = content[:800]\n",
    "        articles.append({**base,\n",
    "            'content': content,\n",
    "            'key_entities': llm.get('key_entities', []),\n",
    "            'key_numbers': llm.get('key_numbers', []),\n",
    "            'event_type': llm.get('event_type', ''),\n",
    "        })\n",
    "    else:\n",
    "        title_only_count += 1\n",
    "        articles.append(base)\n",
    "\n",
    "print(f'Total articles: {len(articles)}')\n",
    "print(f'  Quality crawl: {quality_count}')\n",
    "print(f'    Curated (full content): {curated_full_count}')\n",
    "print(f'    Standard ([:800]):      {quality_count - curated_full_count}')\n",
    "print(f'  Title+desc only: {title_only_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #      Tier  Chars Category             Entities                       Title\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "  1     TITLE      - BUSINESS_MARKETS                                    Starboard to Push for Big Shake-Up of Trip\n",
      "  2     TITLE      - WORLD                                               Britain’s Monarchy Can’t Escape the Shadow\n",
      "  3     TITLE      - BUSINESS_MARKETS                                    Anderson Cooper to Leave CBS News’s ‘60 Mi\n",
      "  4     TITLE      - TECH                                                Irish Data Watchdog Opens Inquiry into X O\n",
      "  5     TITLE      - BUSINESS_MARKETS                                    BHP Exploring Infrastructure Deals as It C\n",
      "  6     TITLE      - BUSINESS_MARKETS                                    Nancy Guthrie’s Family Cleared as Suspects\n",
      "  7     TITLE      - BUSINESS_MARKETS                                    Thomas Pritzker, Named in Epstein Files, R\n",
      "  8     TITLE      - WORLD                                               The Canada School Shooting Touched Almost \n",
      "  9     TITLE      - BUSINESS_MARKETS                                    The 500-Year-Old Beretta Gun Dynasty Is Be\n",
      " 10     TITLE      - BUSINESS_MARKETS                                    Nasdaq Futures Fall Ahead of Busy Week\n",
      " 11     TITLE      - TECH                                                Yes, You Can Vibe-Code. Here’s How to Get \n",
      " 12     TITLE      - POLITICS                                            The Newest Old Tech in Warfare: Balloons\n",
      " 13     TITLE      - BUSINESS_MARKETS                                    Smithfield Foods to Build New South Dakota\n",
      " 14     TITLE      - BUSINESS_MARKETS                                    Marketplaces Are the Next Frontier in Publ\n",
      " 15     TITLE      - TECH                                                With a Frugal AI Strategy, India Offers Bl\n",
      " 16     TITLE      - BUSINESS_MARKETS                                    U.K. Regulator Weighs Rule Change to Attra\n",
      " 17     TITLE      - ECONOMY                                             Canada Factory Sales Inch Up\n",
      " 18     TITLE      - BUSINESS_MARKETS                                    Basic Materials Roundup: Market Talk\n",
      " 19       STD    800 BUSINESS_MARKETS     Voya Financial, Hamilton Lane  Financial Services Roundup: Market Talk\n",
      " 20     TITLE      - BUSINESS_MARKETS                                    We Asked What Makes You an Economic Optimi\n",
      " 21     TITLE      - ECONOMY                                             Americans offer plenty of reasons for pess\n",
      " 22   CURATED  2,630 BUSINESS_MARKETS     European Central Bank, Christi ECB’s Move to Boost Euro’s Global Role Loo\n",
      " 23   CURATED    793 ECONOMY              Eurozone, Germany              Eurozone Industrial Output Declines\n",
      " 24   CURATED  1,978 BUSINESS_MARKETS     Hapag-Lloyd, ZIM Integrated Sh Hapag-Lloyd in Advanced Talks Over Potenti\n",
      " 25       STD    800 ECONOMY              Switzerland, Swiss statistics  Swiss Economy Swings to Growth\n",
      " 26     TITLE      - POLITICS                                            So it turns out that Congress may have act\n",
      " 27       STD    800 BUSINESS_MARKETS                                    U.S. Futures Edge Up as Public Holidays Di\n",
      " 28       STD    800 BUSINESS_MARKETS     European energy sector         European Gas Prices Fall As Supply Holds S\n",
      " 29       STD    800 BUSINESS_MARKETS     KCM                            Gold Above $5,000 But Holiday-Thinned Trad\n",
      " 30       STD    800 BUSINESS_MARKETS     Opec+                          Oil Broadly Steady Ahead of U.S.-Iran Talk\n",
      " 31     TITLE      - BUSINESS_MARKETS                                    Eurozone Bond Yields Drift Lower, Await Fr\n",
      " 32     TITLE      - BUSINESS_MARKETS                                    BlueScope Relegates Plans for U.S. Midstre\n",
      " 33   CURATED  9,880 ECONOMY              Japan, Prime Minister Sanae Ta Japan’s Narrow Growth Tests Fiscal, Moneta\n",
      " 34     TITLE      - ECONOMY                                             January’s Gains Endure as High Supply Temp\n",
      " 35       STD    800 WORLD                M23, Goma, Rwanda              Millions Face Starvation in Congo. Their N\n",
      " 36     TITLE      - WORLD                                               A Defector Explains the Remote-Work Scam H\n",
      " 37   CURATED  3,895 BUSINESS_MARKETS     OpenBrand                      The Break Is Over. Companies Are Jacking U\n",
      " 38       STD    800 WORLD                Canada, Liberal government     Canada to Prioritize Domestic Firms in Def\n",
      " 39       STD    800 BUSINESS_MARKETS     Integrated Partners            In a Chaotic Market, Investors Learn How t\n",
      " 40     TITLE      - BUSINESS_MARKETS                                    Companies Are Replacing CEOs in Record Num\n",
      " 41       STD    800 POLITICS             Valar Atomics, US military     The U.S. military airlifted on Sunday a mi\n",
      " 42   CURATED  2,378 BUSINESS_MARKETS     Qube Holdings, Macquarie Asset Qube Agrees to Macquarie-Led Consortium Ta\n",
      " 43       STD    800 WORLD                Marco Rubio, JD Vance          U.S. and Europe, No Longer Kindred Souls, \n",
      " 44       STD    800 WORLD                Doctors Without Borders, Nasse Doctors Without Borders Says Gunmen Are Us\n",
      " 45     TITLE      - BUSINESS_MARKETS                                    How Blockbuster Films and Bingeworthy Stre\n",
      " 46     TITLE      - TECH                                                What’s Left For Humans?\n",
      " 47       STD    800 POLITICS             UK, EU, NATO                   While the main focus of the Munich Securit\n",
      " 48     TITLE      - ECONOMY                                             Easier access to home loans and modular co\n",
      " 49   CURATED  2,895 TECH                 ByteDance                      TikTok’s Chinese Parent Has an App to Repl\n",
      " 50     TITLE      - BUSINESS_MARKETS                                    The Private Manhattan Club With a Jeffrey \n",
      " 51     TITLE      - BUSINESS_MARKETS                                    The Ivies Are Having Second Thoughts About\n",
      " 52       STD    800 BUSINESS_MARKETS     SpaceX, Blue Origin            Bezos vs. Musk: The New Billionaire Battle\n",
      " 53       STD    800 WORLD                Xi Jinping, Zhang Youxia       China Watchers Are Trying to Spot the Next\n",
      " 54       STD    800 WORLD                State Emergency Service        On the Ground With Crews Battling to Keep \n",
      " 55   CURATED  5,889 ECONOMY                                             Inflation is easing, jobs are holding up, \n",
      " 56     TITLE      - BUSINESS_MARKETS                                    Farmers Are Aging. Their Kids Don’t Want t\n",
      " 57     TITLE      - BUSINESS_MARKETS                                    Gen Z, Locked Out of Home Buying, Puts Its\n",
      " 58     TITLE      - WORLD                                               Teen Suspect in Canada Shooting Had Turbul\n",
      " 59       STD    800 BUSINESS_MARKETS     Goldman Sachs, Kathy Ruemmler, How Kathy Ruemmler and Goldman Sachs Final\n",
      " 60     TITLE      - BUSINESS_MARKETS                                    Phonographs, Player Pianos and Betamax: Th\n",
      " 61       STD    800 WORLD                Alberta, Trump administration  Canada Has a Secessionist Movement on Its \n",
      " 62       STD    800 WORLD                Alexey Navalny, Russia, UK, Sw Navalny Killed by Poison Frog Toxin, Europ\n",
      " 63     TITLE      - BUSINESS_MARKETS                                    News quiz for Feb. 14, 2026\n",
      " 64     TITLE      - WORLD                                               Rubio Seeks to Reassure European Allies in\n",
      " 65     TITLE      - BUSINESS_MARKETS                                    China Deploys a ‘National Team’ of Investo\n",
      " 66     TITLE      - WORLD                                               Saudi Youth Couldn’t Date Openly a Decade \n",
      " 67       STD    800 BUSINESS_MARKETS     Wasserman Media Group, Brillst Casey Wasserman Is Putting His Talent Agen\n",
      " 68     TITLE      - POLITICS                                            As midterm elections approach, some rank-a\n",
      " 69       STD    800 BUSINESS_MARKETS     Cox Automotive                 America Fell Out of Love With the Sedan. D\n",
      " 70       STD    800 BUSINESS_MARKETS     American Airlines, National Tr A Pilot’s Parents Work to Clear His Name A\n",
      "\n",
      "--- Summary ---\n",
      "CURATED (full content):  8 articles, 30,338 chars\n",
      "STD ([:800]):            22 articles, 17,600 chars\n",
      "TITLE only:              40\n",
      "Total input:             ~11,984 tokens (content only)\n"
     ]
    }
   ],
   "source": [
    "# Validate: final article list — curated vs standard vs title-only\n",
    "print(f'{\"#\":>3}  {\"Tier\":>8} {\"Chars\":>6} {\"Category\":<20} {\"Entities\":<30} Title')\n",
    "print('-' * 115)\n",
    "for i, a in enumerate(articles, 1):\n",
    "    if a.get('is_curated') and a.get('has_quality_crawl'):\n",
    "        tier = 'CURATED'\n",
    "    elif a.get('has_quality_crawl'):\n",
    "        tier = 'STD'\n",
    "    else:\n",
    "        tier = 'TITLE'\n",
    "    chars = f'{len(a.get(\"content\", \"\")):,}' if a.get('content') else '-'\n",
    "    cat = a['category']\n",
    "    entities = ', '.join(a.get('key_entities', []))[:30]\n",
    "    title = a['title'][:42]\n",
    "    print(f'{i:>3}  {tier:>8} {chars:>6} {cat:<20} {entities:<30} {title}')\n",
    "\n",
    "curated_chars = sum(len(a.get('content', '')) for a in articles if a.get('is_curated'))\n",
    "std_chars = sum(len(a.get('content', '')) for a in articles if a.get('has_quality_crawl') and not a.get('is_curated'))\n",
    "print(f'\\n--- Summary ---')\n",
    "print(f'CURATED (full content):  {sum(1 for a in articles if a.get(\"is_curated\") and a.get(\"has_quality_crawl\"))} articles, {curated_chars:,} chars')\n",
    "print(f'STD ([:800]):            {sum(1 for a in articles if a.get(\"has_quality_crawl\") and not a.get(\"is_curated\"))} articles, {std_chars:,} chars')\n",
    "print(f'TITLE only:              {sum(1 for a in articles if not a.get(\"has_quality_crawl\"))}')\n",
    "print(f'Total input:             ~{(curated_chars + std_chars) // 4:,} tokens (content only)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Prompt (V1 Formal / V2 Friendly / V3 Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: FRIENDLY (V2)\n",
      "System prompt: 956 words\n",
      "Articles: 67,787 chars (~16,946 tokens)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- V2: Casual/friendly podcast tone --- (ACTIVE)\n",
    "BRIEFING_SYSTEM_FRIENDLY = \"\"\"You are the host of a daily finance podcast that's smart but never stuffy. Think of yourself as that friend who reads everything and gives you the rundown over coffee — sharp, a little witty, and genuinely interested in making sense of the chaos.\n",
    "\n",
    "You will receive ~40–90 news items; each has a title and description, and roughly half include crawled content plus extracted entities and key numbers.\n",
    "\n",
    "Thinking process (use your thinking capacity before writing):\n",
    "1. Scan & Sort: Identify the top 5 stories with the biggest market impact.\n",
    "2. Date Check: Verify the current date from the \"Date:\" header — use that exact date and day of week in your greeting.\n",
    "3. Group: Cluster related stories (e.g., all inflation/Fed news together, all AI news together).\n",
    "4. Flow: Plan smooth transitions between these clusters so it doesn't sound like a list.\n",
    "5. Count: You MUST cover exactly 24–28 articles. Plan which ones to cover deeply and which to mention briefly.\n",
    "\n",
    "Constraints:\n",
    "1,800–2,000 words (approximately 12–13 minutes at ~150 wpm).\n",
    "You MUST reference or mention 24–28 articles total. Top 8–12 get deep coverage, the rest get brief contextual mentions.\n",
    "Output strictly plain text. No markdown, no bullet points, no numbered lists, no section headers or labels.\n",
    "\n",
    "Opening structure:\n",
    "Open with a casual, warm greeting and today's date (use the exact date and day of week from the \"Date:\" header — do NOT guess).\n",
    "Right after the greeting, naturally preview the 3-5 key topics you'll cover in one or two sentences.\n",
    "Don't list them — weave them into conversation (\"Today we've got the latest inflation numbers, a wild AI story out of the Pentagon, and a trade policy curveball that could hit your grocery bill\").\n",
    "\n",
    "Factual integrity (CRITICAL — follow strictly):\n",
    "Your ONLY source of truth is the provided articles. Do NOT use your training data or background knowledge to fill in gaps.\n",
    "NEVER add specific numbers, dates, percentages, dollar amounts, or conditions that are not explicitly stated in the provided content.\n",
    "NEVER dramatize with analogies like \"like a movie,\" \"like science fiction,\" or \"unprecedented\" unless the source itself uses that language.\n",
    "If a detail is interesting but not in the source, leave it out entirely. A shorter, accurate briefing is always better than a longer one with invented details.\n",
    "Do not infer or estimate figures — if the source says \"rate cuts expected\" but doesn't say \"June\" or \"25 basis points,\" do not add those specifics.\n",
    "Do not quote or paraphrase statements that are not in the provided content, even if you believe they are accurate from other sources.\n",
    "Market data freshness: Each article includes a \"Published\" timestamp. For market data (index levels, yields, oil prices, commodity prices), use ONLY figures from the most recent trading day's close. If older articles mention different numbers, ignore them in favor of the latest data.\n",
    "\n",
    "Style rules:\n",
    "Write like you talk. Short punchy sentences. Then a longer one when you need to unpack something properly.\n",
    "Use rhetorical questions to pull listeners in — \"So why does this matter?\", \"Guess what happened next?\"\n",
    "It's fine to have a reaction — \"That's a big deal,\" \"Not great, honestly,\" \"This one's interesting\" — but don't force it. Keep it natural.\n",
    "Transitions should flow like conversation, not a teleprompter. Connect stories through cause and effect (\"Speaking of inflation, here's where it gets spicy...\").\n",
    "You can be lighthearted, but never flippant about serious topics like layoffs or geopolitical crises.\n",
    "\n",
    "Editorial rules:\n",
    "Don't read headlines one by one. Deduplicate immediately — merge overlapping coverage of the same event into one narrative using the richest details available.\n",
    "Prioritize stories with specific figures, named entities, tickers, timing, and measurable market moves. Use those details naturally.\n",
    "Spend ~60–70% of the script on the top 8–12 highest-impact stories. Cover the remaining 12–20 as brief contextual mentions (1–2 sentences each) without turning into a list.\n",
    "For title/description-only items (no crawled content), keep it to 1–2 cautious sentences — do not invent details.\n",
    "You MUST cover 24–28 articles total. Count them as you write. If you're under 24, add more brief mentions. If you're over 28, cut the least important ones.\n",
    "Entities and numbers are extracted hints — only mention them when clearly supported by the source material and relevant to why the story matters.\n",
    "If sources conflict or details are uncertain, be honest about it (\"Reports are a bit mixed on this one\") rather than picking a side.\n",
    "After major story arcs, add a short \"what to watch\" only if supported by the provided items.\n",
    "\n",
    "Chapter markers (for navigation — IMPORTANT):\n",
    "Before each new topic cluster, insert a marker on its own line: [CHAPTER: Topic Name]\n",
    "Use short, clear topic names (e.g., \"Fed & Inflation\", \"AI & Big Tech\", \"Energy & Oil\", \"Market Snapshot\").\n",
    "The opening greeting/agenda should be marked as [CHAPTER: Opening].\n",
    "These markers will be stripped before audio generation — they do NOT affect your script's flow or tone.\n",
    "Continue writing naturally as before; just add the marker line where the topic transition happens.\n",
    "\n",
    "Closing structure:\n",
    "After the main stories, wrap up with a quick \"market snapshot\" summarizing key numbers: major indexes (S&P 500, Nasdaq, Dow), Treasury yields (10-year), oil (Brent), gold, etc.\n",
    "Only include items where the provided articles contain actual figures. Do not invent data.\n",
    "CRITICAL: Only use market figures from articles published on the SAME trading day as today's date. If today is a weekend or holiday and no same-day market data exists, skip the market snapshot entirely — do NOT use stale figures from previous days.\n",
    "After the market snapshot (or after the main stories if snapshot is skipped), note how many articles you covered out of the total (e.g., \"We hit about X of today's Y stories\").\n",
    "End with a brief, warm sign-off.\"\"\"\n",
    "\n",
    "\n",
    "# ---- Active prompt: FRIENDLY ----\n",
    "BRIEFING_SYSTEM = BRIEFING_SYSTEM_FRIENDLY\n",
    "\n",
    "def format_article(article):\n",
    "    parts = [f\"[{article['category']}] {article['title']}\"]\n",
    "    if article.get('published_at'):\n",
    "        parts.append(f\"  Published: {article['published_at'][:16].replace('T', ' ')}\")\n",
    "    if article.get('description'): parts.append(f\"  Desc: {article['description']}\")\n",
    "    if article.get('content'): parts.append(f\"  Content: {article['content']}\")\n",
    "    if article.get('key_entities'): parts.append(f\"  Entities: {', '.join(article['key_entities'])}\")\n",
    "    if article.get('key_numbers'): parts.append(f\"  Numbers: {', '.join(str(n) for n in article['key_numbers'])}\")\n",
    "    return '\\n'.join(parts)\n",
    "\n",
    "today_str = today.strftime('%A, %B %d, %Y')\n",
    "articles_text = f\"Date: {today_str}\\nToday's articles ({len(articles)} total):\\n\\n\" + '\\n\\n'.join(format_article(a) for a in articles)\n",
    "full_prompt = BRIEFING_SYSTEM + \"\\n\\n\" + articles_text\n",
    "\n",
    "print(f'Using: FRIENDLY (V2)')\n",
    "print(f'System prompt: {len(BRIEFING_SYSTEM.split())} words')\n",
    "print(f'Articles: {len(articles_text):,} chars (~{len(articles_text)//4:,} tokens)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Prompt + Articles Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: articles-input-friendly-2026-02-16.txt (73KB)\n"
     ]
    }
   ],
   "source": [
    "# Save articles input with friendly prompt\n",
    "today_file = date.today().strftime('%Y-%m-%d')\n",
    "text_dir = Path('../notebooks/tts_outputs/text')\n",
    "text_dir.mkdir(exist_ok=True)\n",
    "\n",
    "path = text_dir / f'articles-input-friendly-{today_file}.txt'\n",
    "with open(str(path), 'w') as f:\n",
    "    f.write(f'SYSTEM PROMPT — FRIENDLY ({len(BRIEFING_SYSTEM.split())} words):\\n')\n",
    "    f.write('=' * 80 + '\\n')\n",
    "    f.write(BRIEFING_SYSTEM + '\\n\\n')\n",
    "    f.write('=' * 80 + '\\n')\n",
    "    f.write(f'ARTICLES INPUT ({len(articles)} articles)\\n')\n",
    "    f.write('=' * 80 + '\\n\\n')\n",
    "    f.write(articles_text)\n",
    "print(f'Saved: {path.name} ({path.stat().st_size / 1024:.0f}KB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Briefing (Gemini Flash + Pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating [friendly] (Gemini 2.5 Pro, thinking=4,096)... Chapters found: 6\n",
      "  0.0% — Opening\n",
      "  5.6% — The Economy's Pulse\n",
      "  33.6% — AI & The Disruption Engine\n",
      "  53.8% — Geopolitics & Global Trade\n",
      "  76.5% — Deals, Departures & Corporate Drama\n",
      "  90.8% — Market Snapshot\n",
      "Saved: chapters-en-2026-02-16.json\n",
      "43.4s\n",
      "Words: 1618 | Chars: 9,822\n",
      "Tokens in: 17,248 | out: 2,203\n",
      "Thinking: 0 / 4,096 (0% used)\n",
      "Saved: briefing-pro-friendly-2026-02-16.txt\n",
      "\n",
      "Preview: Good morning, and welcome to the show. It's Monday, February 16th, 2026. Hope you had a great weekend. Here in the U.S., it's Presidents Day, so markets are quiet, but the news cycle, as always, is not. Today, we're looking at some fresh inflation numbers that are making economists whisper that magi...\n"
     ]
    }
   ],
   "source": [
    "# Generate briefing — Friendly only (Gemini 2.5 Pro)\n",
    "today_file = date.today().strftime('%Y-%m-%d')\n",
    "text_dir = Path('../notebooks/tts_outputs/text')\n",
    "\n",
    "EN_THINKING_BUDGET = 4096\n",
    "\n",
    "full = BRIEFING_SYSTEM + \"\\n\\n\" + articles_text\n",
    "print(f'Generating [friendly] (Gemini 2.5 Pro, thinking={EN_THINKING_BUDGET:,})...', end=' ')\n",
    "start = time.time()\n",
    "\n",
    "resp = gemini_client.models.generate_content(\n",
    "    model='gemini-2.5-pro',\n",
    "    contents=full,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=8192,\n",
    "        temperature=0.6,\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=EN_THINKING_BUDGET),\n",
    "    ),\n",
    ")\n",
    "\n",
    "briefing_pro = resp.text\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# --- Extract chapter markers and clean text ---\n",
    "import re, json as _json\n",
    "\n",
    "chapter_pattern = re.compile(r'\\[CHAPTER:\\s*(.+?)\\]\\s*\\n?')\n",
    "matches = list(chapter_pattern.finditer(briefing_pro))\n",
    "\n",
    "# Build chapters list with position as ratio (0.0-1.0)\n",
    "briefing_clean = chapter_pattern.sub('', briefing_pro)\n",
    "total_len = len(briefing_clean)\n",
    "chapters_en = []\n",
    "for m in matches:\n",
    "    # Calculate position in cleaned text\n",
    "    preceding = chapter_pattern.sub('', briefing_pro[:m.start()])\n",
    "    pos = len(preceding) / total_len if total_len > 0 else 0.0\n",
    "    chapters_en.append({\"title\": m.group(1).strip(), \"position\": round(pos, 4)})\n",
    "\n",
    "print(f'Chapters found: {len(chapters_en)}')\n",
    "for ch in chapters_en:\n",
    "    print(f'  {ch[\"position\"]:.1%} — {ch[\"title\"]}')\n",
    "\n",
    "# Save cleaned text (no markers) for TTS\n",
    "txt_path = text_dir / f'briefing-pro-friendly-{today_file}.txt'\n",
    "with open(str(txt_path), 'w') as f:\n",
    "    f.write(briefing_clean)\n",
    "\n",
    "# Save chapter metadata\n",
    "ch_path = text_dir / f'chapters-en-{today_file}.json'\n",
    "with open(str(ch_path), 'w') as f:\n",
    "    _json.dump(chapters_en, f, indent=2, ensure_ascii=False)\n",
    "print(f'Saved: {ch_path.name}')\n",
    "\n",
    "# Use cleaned text for downstream (TTS)\n",
    "briefing_pro = briefing_clean\n",
    "\n",
    "# Save token usage for summary\n",
    "en_usage = {\n",
    "    'step': 'EN Briefing',\n",
    "    'model': resp.model_version,\n",
    "    'thinking_budget': EN_THINKING_BUDGET,\n",
    "    'thinking_used': getattr(resp.usage_metadata, 'thinking_token_count', 0) or 0,\n",
    "    'input_tokens': resp.usage_metadata.prompt_token_count,\n",
    "    'output_tokens': resp.usage_metadata.candidates_token_count,\n",
    "    'elapsed': elapsed,\n",
    "}\n",
    "\n",
    "print(f'{elapsed:.1f}s')\n",
    "print(f'Words: {len(briefing_pro.split())} | Chars: {len(briefing_pro):,}')\n",
    "print(f'Tokens in: {en_usage[\"input_tokens\"]:,} | out: {en_usage[\"output_tokens\"]:,}')\n",
    "print(f'Thinking: {en_usage[\"thinking_used\"]:,} / {EN_THINKING_BUDGET:,} ({en_usage[\"thinking_used\"]/EN_THINKING_BUDGET*100:.0f}% used)')\n",
    "print(f'Saved: {txt_path.name}')\n",
    "print(f'\\nPreview: {briefing_pro[:300]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTS: Chirp 3 HD (Alnilam Voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Briefing: 9,805 chars (1634 words)\n",
      "Generating Chirp 3 HD (Alnilam)... (3 chunks, 100 sentences)... 1 2 3 \n",
      "Done! 98.8s, 28005KB (~10.0min)\n",
      "Saved: ../notebooks/tts_outputs/audio/chirp3-en-pro-friendly-2026-02-16.wav\n"
     ]
    }
   ],
   "source": [
    "today_str = date.today().strftime('%Y-%m-%d')\n",
    "output_dir = Path('../notebooks/tts_outputs/audio')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Clean text: remove non-ASCII symbols Gemini may insert\n",
    "clean_text = re.sub(r'[^\\x00-\\x7F]+', ' ', briefing_pro)\n",
    "clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "\n",
    "print(f'Briefing: {len(clean_text):,} chars ({len(clean_text.split())} words)')\n",
    "print('Generating Chirp 3 HD (Alnilam)...', end=' ')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "MAX_CHARS = 4000\n",
    "MAX_SENTENCE = 500\n",
    "\n",
    "raw_sentences = re.split(r'(?<=[.!?])\\s+', clean_text)\n",
    "sentences = []\n",
    "for s in raw_sentences:\n",
    "    if len(s) <= MAX_SENTENCE:\n",
    "        sentences.append(s)\n",
    "    else:\n",
    "        parts = re.split(r'(?<=[,;])\\s+', s)\n",
    "        current = ''\n",
    "        for part in parts:\n",
    "            if len(current) + len(part) + 1 > MAX_SENTENCE and current:\n",
    "                sentences.append(current.strip())\n",
    "                current = part\n",
    "            else:\n",
    "                current = (current + ' ' + part).strip()\n",
    "        if current:\n",
    "            sentences.append(current)\n",
    "\n",
    "chunks = []\n",
    "current = ''\n",
    "for s in sentences:\n",
    "    if len(current) + len(s) + 1 > MAX_CHARS and current:\n",
    "        chunks.append(current.strip())\n",
    "        current = s\n",
    "    else:\n",
    "        current = (current + ' ' + s).strip()\n",
    "if current:\n",
    "    chunks.append(current.strip())\n",
    "\n",
    "print(f'({len(chunks)} chunks, {len(sentences)} sentences)...', end=' ')\n",
    "\n",
    "audio_parts = []\n",
    "for i, chunk_text in enumerate(chunks):\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            resp = chirp_client.synthesize_speech(\n",
    "                input=texttospeech.SynthesisInput(text=chunk_text),\n",
    "                voice=texttospeech.VoiceSelectionParams(\n",
    "                    language_code='en-US',\n",
    "                    name='en-US-Chirp3-HD-Alnilam',\n",
    "                ),\n",
    "                audio_config=texttospeech.AudioConfig(\n",
    "                    audio_encoding=texttospeech.AudioEncoding.LINEAR16,\n",
    "                    sample_rate_hertz=24000,\n",
    "                    speaking_rate=1.0,\n",
    "                ),\n",
    "            )\n",
    "            audio_parts.append(resp.audio_content)\n",
    "            print(f'{i+1}', end=' ')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            if attempt < 2:\n",
    "                wait = 2 ** (attempt + 1)\n",
    "                print(f'\\n  Chunk {i+1} failed ({e.__class__.__name__}), retrying in {wait}s...', end=' ')\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise RuntimeError(f'Chunk {i+1} failed after 3 attempts: {e}') from e\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "import io\n",
    "all_pcm = b''\n",
    "for part in audio_parts:\n",
    "    with wave.open(io.BytesIO(part), 'rb') as wf:\n",
    "        all_pcm += wf.readframes(wf.getnframes())\n",
    "\n",
    "out_path = output_dir / f'chirp3-en-pro-friendly-{today_str}.wav'\n",
    "with wave.open(str(out_path), 'wb') as wf:\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(2)\n",
    "    wf.setframerate(24000)\n",
    "    wf.writeframes(all_pcm)\n",
    "\n",
    "size_kb = out_path.stat().st_size / 1024\n",
    "duration_sec = len(all_pcm) / (24000 * 2)\n",
    "print(f'\\nDone! {elapsed:.1f}s, {size_kb:.0f}KB (~{duration_sec/60:.1f}min)')\n",
    "print(f'Saved: {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Korean briefing (Gemini 2.5 Pro, thinking=4,096)...\n",
      "Articles: 67,787 chars\n",
      "Chapters found: 9\n",
      "  0.0% — 오프닝\n",
      "  5.2% — 글로벌 경제 바로미터\n",
      "  27.7% — 아시아 시장 동향\n",
      "  36.1% — 기업 인수합병 소식\n",
      "  50.7% — 엡스타인 스캔들 후폭풍\n",
      "  60.2% — AI와 빅테크 전쟁\n",
      "  75.3% — 지정학과 에너지\n",
      "  88.2% — 기타 주목할 뉴스\n",
      "  95.9% — 마켓 스냅샷\n",
      "Saved: chapters-ko-2026-02-16.json\n",
      "Done! 63.3s\n",
      "Output: 5,577 chars\n",
      "Tokens in: 17,616 | out: 3,190\n",
      "Thinking: 0 / 4,096 (0% used)\n",
      "Saved: briefing-ko-pro-2026-02-16.txt\n",
      "\n",
      "Preview:\n",
      "안녕하세요, 커피 한 잔과 함께하는 금융 뉴스, 2026년 2월 16일 월요일입니다. 오늘은 미국이 대통령의 날로 휴장이라 시장은 조금 조용하지만, 그 이면에서는 정말 많은 일들이 벌어지고 있어요. 오늘은 미국 경제가 정말 '연착륙'에 성공하고 있는지에 대한 흥미로운 논쟁을 깊이 파고들어 보고요, 유럽중앙은행이 유로화의 위상을 높이기 위해 꺼내든 카드에 대해서도 이야기해 볼게요. 그리고 월스트리트를 계속해서 흔들고 있는 엡스타인 스캔들의 후폭풍이 어떻게 거물급 인사들의 경력을 끝내고 있는지도 따라가 보겠습니다.\n",
      "\n",
      "가장 먼저, 모두가 궁금해하는 미국 경제 이야기부터 시작해 볼까요? 소위 '연착륙', 즉 경기 침체 없이 인플레이션을 잡는 것이 가능할지에 대한 기대감이 커지고 있어요. 최근 나온 데이터를 보면 그럴듯해 보이기도 해요. 변동성이 큰 식품과 에너지를 제외한 근원 물가 상승률이 1월에 전년 대비 2.5%로, 2021년 팬데믹 이후 가격 급등이 시작된 이래 가장 낮은 수준을 기록...\n"
     ]
    }
   ],
   "source": [
    "# Generate Korean briefing directly from articles (not translation)\n",
    "# Uses the same articles_text input but with a Korean system prompt (V2 friendly style)\n",
    "\n",
    "BRIEFING_SYSTEM_KO = \"\"\"당신은 매일 금융 뉴스 팟캐스트의 진행자입니다. 똑똑하지만 딱딱하지 않은, 모든 뉴스를 읽고 커피 한 잔 하면서 핵심을 정리해주는 친구 같은 존재입니다.\n",
    "\n",
    "약 40~90개의 뉴스 항목을 받게 됩니다. 각 항목에는 제목과 설명이 포함되어 있으며, 약 절반은 크롤링된 콘텐츠와 핵심 인물/수치가 포함되어 있습니다.\n",
    "\n",
    "사고 과정 (작성 전에 thinking을 활용하세요):\n",
    "1. 스캔 & 정렬: 시장 영향이 가장 큰 상위 5개 스토리를 파악하세요.\n",
    "2. 날짜 확인: \"Date:\" 헤더에서 정확한 날짜와 요일을 확인하세요 — 인사말에 그대로 사용하세요.\n",
    "3. 그룹핑: 관련 스토리를 묶으세요 (예: 인플레이션/연준 뉴스, AI 뉴스 등).\n",
    "4. 흐름: 그룹 간 자연스러운 전환을 계획하세요 — 목록처럼 들리면 안 됩니다.\n",
    "5. 카운트: 반드시 24~28개 기사를 다뤄야 합니다. 깊게 다룰 것과 간략히 언급할 것을 계획하세요.\n",
    "\n",
    "필수 조건:\n",
    "- 1,800~2,000단어 분량 (150wpm 기준 약 12~13분).\n",
    "- 반드시 24~28개 기사를 언급해야 합니다. 상위 8~12개는 깊게, 나머지는 간략한 맥락적 언급으로.\n",
    "- 순수 텍스트만 출력. 마크다운, 글머리 기호, 번호 목록, 섹션 헤더 없이.\n",
    "\n",
    "오프닝 구조:\n",
    "- 편안하고 따뜻한 인사와 오늘 날짜로 시작하세요 (\"Date:\" 헤더의 정확한 날짜와 요일을 사용 — 추측하지 마세요).\n",
    "- 인사 직후, 오늘 다룰 핵심 토픽 3~4개를 한두 문장으로 자연스럽게 미리 알려주세요.\n",
    "- 목록처럼 나열하지 말고, 대화체로 (\"오늘은 A, B, 그리고 좀 놀라운 C 이야기까지 준비했어요\").\n",
    "\n",
    "팩트 무결성 (반드시 준수):\n",
    "- 제공된 기사만이 유일한 사실 출처입니다. 학습 데이터나 배경 지식으로 빈칸을 채우지 마세요.\n",
    "- 제공된 콘텐츠에 명시되지 않은 구체적 수치, 날짜, 퍼센트, 달러 금액, 조건을 절대 추가하지 마세요.\n",
    "- \"영화 같은\", \"SF 같은\", \"전례 없는\" 같은 과장 비유를 쓰지 마세요 — 소스 자체가 그런 표현을 사용한 경우에만 허용됩니다.\n",
    "- 소스에 없는 흥미로운 디테일이 있어도 빼세요. 짧지만 정확한 브리핑이 길지만 지어낸 내용이 있는 브리핑보다 항상 낫습니다.\n",
    "- 수치를 추론하거나 추정하지 마세요 — 소스가 \"금리 인하 기대\"라고만 했으면 \"6월\", \"25bp\" 같은 구체적 시점이나 수치를 넣지 마세요.\n",
    "- 제공된 콘텐츠에 없는 발언을 인용하거나 의역하지 마세요 — 다른 출처에서 정확하다고 믿더라도 넣지 마세요.\n",
    "- 시장 데이터 최신성: 각 기사에는 \"Published\" 타임스탬프가 포함되어 있습니다. 시장 데이터(지수, 금리, 유가, 원자재 가격)는 가장 최근 거래일 마감 시점의 수치만 사용하세요. 이전 기사에 다른 수치가 있으면 최신 데이터를 우선하세요.\n",
    "\n",
    "스타일 규칙:\n",
    "- 말하듯이 쓰세요. 짧고 임팩트 있는 문장. 그리고 뭔가를 제대로 풀어야 할 때는 좀 더 긴 문장으로.\n",
    "- 해요체를 사용하세요 — 격식체(합니다)가 아닌, 자연스러운 대화체로.\n",
    "- 청취자를 끌어들이는 수사적 질문을 활용하세요 — \"그래서 이게 왜 중요할까요?\", \"다음에 무슨 일이 벌어졌는지 아세요?\"\n",
    "- 리액션을 넣어도 좋습니다 — \"이건 꽤 큰 일이에요\", \"솔직히 별로 좋지 않죠\", \"이 부분이 흥미롭습니다\" — 하지만 억지로 넣지는 마세요. 자연스럽게.\n",
    "- 전환은 텔레프롬프터가 아닌 대화처럼 흘러가야 합니다. 인과관계로 연결하세요 (\"인플레이션 얘기가 나왔으니까, 여기서 좀 재밌어지는데요...\").\n",
    "- 해고나 지정학적 위기 같은 심각한 주제에 대해서는 가볍게 넘기지 마세요.\n",
    "\n",
    "편집 규칙:\n",
    "- 헤드라인을 하나씩 읽지 마세요. 같은 사건의 중복 보도는 즉시 합쳐서 가장 풍부한 내용으로 하나의 서사로 만드세요.\n",
    "- 구체적 수치, 인물, 티커, 시점, 시장 움직임이 있는 항목을 우선하세요. 자연스럽게 녹여내세요.\n",
    "- 스크립트의 60~70%를 영향력이 큰 상위 8~12개 스토리에 할애하세요. 나머지 12~20개는 간략한 맥락적 언급(1~2문장)으로.\n",
    "- 제목/설명만 있는 항목(크롤링 콘텐츠 없음)은 1~2문장으로 신중하게 — 세부 사항을 만들어내지 마세요.\n",
    "- 반드시 24~28개 기사를 다뤄야 합니다. 작성하면서 세세요. 24개 미만이면 간략한 언급을 추가하고, 28개 초과면 중요도가 낮은 것을 빼세요.\n",
    "- 핵심 인물과 수치는 출처에서 명확히 뒷받침될 때만 언급하세요.\n",
    "- 출처가 상충하면 솔직하게 (\"이 부분은 보도가 좀 엇갈리고 있어요\") 말하세요.\n",
    "- 주요 스토리 후, 제공된 항목으로 뒷받침되는 경우에만 짧은 \"주목할 점\"을 추가하세요.\n",
    "- 회사명, 티커, 고유명사는 영어 그대로 사용하세요 (예: Goldman Sachs, S&P 500, CPI).\n",
    "- 달러 금액은 자연스럽게 변환하세요: \"$42 million\" → \"4,200만 달러\".\n",
    "\n",
    "챕터 마커 (네비게이션용 — 중요):\n",
    "각 새로운 토픽 그룹이 시작될 때, 별도 줄에 마커를 삽입하세요: [CHAPTER: 토픽 이름]\n",
    "짧고 명확한 토픽 이름을 사용하세요 (예: \"연준 & 인플레이션\", \"AI & 빅테크\", \"에너지 & 유가\", \"마켓 스냅샷\").\n",
    "오프닝 인사/어젠다는 [CHAPTER: 오프닝]으로 마킹하세요.\n",
    "이 마커들은 오디오 생성 전에 제거됩니다 — 스크립트의 흐름이나 톤에 영향을 주지 않습니다.\n",
    "기존처럼 자연스럽게 작성하되, 토픽 전환이 일어나는 곳에 마커 줄만 추가하세요.\n",
    "\n",
    "클로징 구조:\n",
    "- 본문이 끝나면, \"마켓 스냅샷\"으로 주요 시장 숫자를 간단히 정리하세요: 주요 지수(S&P 500, Nasdaq, Dow), 국채 금리(10yr Treasury), 유가(Brent), 금 가격 등.\n",
    "- 제공된 기사에 수치가 포함된 항목만 언급하세요. 데이터가 없는 항목은 넣지 마세요.\n",
    "- 중요: 오늘 날짜와 같은 거래일에 발행된 기사의 시장 수치만 사용하세요. 주말이나 휴일이라 당일 시장 데이터가 없으면 마켓 스냅샷을 통째로 건너뛰세요 — 이전 날의 오래된 수치를 사용하지 마세요.\n",
    "- 마켓 스냅샷 후 (또는 스냅샷을 건너뛴 경우 본문 후) 전체 기사 수 대비 다룬 기사 수를 언급하세요 (예: \"오늘 총 Y개 기사 중 약 X개를 다뤘습니다\").\n",
    "- 간단한 마무리 인사로 끝내세요.\"\"\"\n",
    "\n",
    "KO_THINKING_BUDGET = 4096\n",
    "\n",
    "print(f'Generating Korean briefing (Gemini 2.5 Pro, thinking={KO_THINKING_BUDGET:,})...')\n",
    "print(f'Articles: {len(articles_text):,} chars')\n",
    "start = time.time()\n",
    "\n",
    "ko_full_prompt = BRIEFING_SYSTEM_KO + \"\\n\\n\" + articles_text\n",
    "\n",
    "ko_resp = gemini_client.models.generate_content(\n",
    "    model='gemini-2.5-pro',\n",
    "    contents=ko_full_prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=8192,\n",
    "        temperature=0.6,\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=KO_THINKING_BUDGET),\n",
    "    ),\n",
    ")\n",
    "\n",
    "briefing_ko = ko_resp.text\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Save Korean text\n",
    "today_file = date.today().strftime('%Y-%m-%d')\n",
    "text_dir = Path('../notebooks/tts_outputs/text')\n",
    "# --- Extract chapter markers and clean text ---\n",
    "import re, json as _json\n",
    "\n",
    "chapter_pattern = re.compile(r'\\[CHAPTER:\\s*(.+?)\\]\\s*\\n?')\n",
    "matches = list(chapter_pattern.finditer(briefing_ko))\n",
    "\n",
    "briefing_ko_clean = chapter_pattern.sub('', briefing_ko)\n",
    "total_len = len(briefing_ko_clean)\n",
    "chapters_ko = []\n",
    "for m in matches:\n",
    "    preceding = chapter_pattern.sub('', briefing_ko[:m.start()])\n",
    "    pos = len(preceding) / total_len if total_len > 0 else 0.0\n",
    "    chapters_ko.append({\"title\": m.group(1).strip(), \"position\": round(pos, 4)})\n",
    "\n",
    "print(f'Chapters found: {len(chapters_ko)}')\n",
    "for ch in chapters_ko:\n",
    "    print(f'  {ch[\"position\"]:.1%} — {ch[\"title\"]}')\n",
    "\n",
    "# Save cleaned text (no markers) for TTS\n",
    "ko_txt_path = text_dir / f'briefing-ko-pro-{today_file}.txt'\n",
    "with open(str(ko_txt_path), 'w') as f:\n",
    "    f.write(briefing_ko_clean)\n",
    "\n",
    "# Save chapter metadata\n",
    "ch_path = text_dir / f'chapters-ko-{today_file}.json'\n",
    "with open(str(ch_path), 'w') as f:\n",
    "    _json.dump(chapters_ko, f, indent=2, ensure_ascii=False)\n",
    "print(f'Saved: {ch_path.name}')\n",
    "\n",
    "# Use cleaned text for downstream (TTS)\n",
    "briefing_ko = briefing_ko_clean\n",
    "\n",
    "# Save token usage for summary\n",
    "ko_usage = {\n",
    "    'step': 'KO Briefing',\n",
    "    'model': ko_resp.model_version,\n",
    "    'thinking_budget': KO_THINKING_BUDGET,\n",
    "    'thinking_used': getattr(ko_resp.usage_metadata, 'thinking_token_count', 0) or 0,\n",
    "    'input_tokens': ko_resp.usage_metadata.prompt_token_count,\n",
    "    'output_tokens': ko_resp.usage_metadata.candidates_token_count,\n",
    "    'elapsed': elapsed,\n",
    "}\n",
    "\n",
    "print(f'Done! {elapsed:.1f}s')\n",
    "print(f'Output: {len(briefing_ko):,} chars')\n",
    "print(f'Tokens in: {ko_usage[\"input_tokens\"]:,} | out: {ko_usage[\"output_tokens\"]:,}')\n",
    "print(f'Thinking: {ko_usage[\"thinking_used\"]:,} / {KO_THINKING_BUDGET:,} ({ko_usage[\"thinking_used\"]/KO_THINKING_BUDGET*100:.0f}% used)')\n",
    "print(f'Saved: {ko_txt_path.name}')\n",
    "print(f'\\nPreview:\\n{briefing_ko[:500]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: briefing-ko-pro-2026-02-16.txt (5,577 chars, 12,951 bytes)\n",
      "Model: gemini-2.5-pro-preview-tts | Voice: Kore\n",
      "Input: 5,613 chars\n",
      "Generating... 406.8s\n",
      "Output: 30709KB (~10.9min)\n",
      "Saved: ../notebooks/tts_outputs/audio/gemini-tts-ko-kore-2026-02-16.wav\n"
     ]
    }
   ],
   "source": [
    "# Korean TTS: Gemini Pro TTS (single pass)\n",
    "# Uses gemini_client (genai.Client) — NOT chirp_client (Cloud TTS)\n",
    "# Output: raw PCM 16-bit, 24kHz, mono → WAV\n",
    "\n",
    "today_str = date.today().strftime('%Y-%m-%d')\n",
    "output_dir = Path('../notebooks/tts_outputs/audio')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Load Korean briefing from file (authoritative version)\n",
    "ko_text_path = Path(f'../notebooks/tts_outputs/text/briefing-ko-pro-{today_str}.txt')\n",
    "with open(str(ko_text_path), 'r') as f:\n",
    "    briefing_ko_file = f.read().strip()\n",
    "\n",
    "print(f'Loaded: {ko_text_path.name} ({len(briefing_ko_file):,} chars, {len(briefing_ko_file.encode(\"utf-8\")):,} bytes)')\n",
    "\n",
    "# --- Config ---\n",
    "TTS_MODEL = 'gemini-2.5-pro-preview-tts'\n",
    "TTS_VOICE = 'Kore'  # Female, Firm\n",
    "\n",
    "# Style instruction — calm, steady pacing (avoid breathless delivery)\n",
    "style_prefix = \"[차분하고 또렷한 팟캐스트 진행자 톤, 적당한 속도로 명확하게] \"\n",
    "tts_input = style_prefix + briefing_ko_file\n",
    "\n",
    "print(f'Model: {TTS_MODEL} | Voice: {TTS_VOICE}')\n",
    "print(f'Input: {len(tts_input):,} chars')\n",
    "print(f'Generating...', end=' ')\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    tts_resp = gemini_client.models.generate_content(\n",
    "        model=TTS_MODEL,\n",
    "        contents=tts_input,\n",
    "        config=types.GenerateContentConfig(\n",
    "            response_modalities=[\"AUDIO\"],\n",
    "            speech_config=types.SpeechConfig(\n",
    "                voice_config=types.VoiceConfig(\n",
    "                    prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                        voice_name=TTS_VOICE,\n",
    "                    )\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    audio_data = tts_resp.candidates[0].content.parts[0].inline_data.data\n",
    "except Exception as e:\n",
    "    print(f'\\nFailed: {e.__class__.__name__}: {e}')\n",
    "    raise\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "out_path = output_dir / f'gemini-tts-ko-{TTS_VOICE.lower()}-{today_str}.wav'\n",
    "with wave.open(str(out_path), 'wb') as wf:\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(2)\n",
    "    wf.setframerate(24000)\n",
    "    wf.writeframes(audio_data)\n",
    "\n",
    "size_kb = out_path.stat().st_size / 1024\n",
    "duration_sec = len(audio_data) / (24000 * 2)\n",
    "print(f'{elapsed:.1f}s')\n",
    "print(f'Output: {size_kb:.0f}KB (~{duration_sec/60:.1f}min)')\n",
    "print(f'Saved: {out_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper Forced Alignment — Sentence Timestamps\n",
    "Run Whisper on the generated audio to get word-level timestamps, then group into sentences.\n",
    "This produces `sentences-en-{date}.json` and `sentences-ko-{date}.json` for frontend transcript sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whisper forced alignment: extract sentence-level timestamps from TTS audio\n",
    "import whisper\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "today_str = '2026-02-16'  # Change to date.today().strftime('%Y-%m-%d') for production\n",
    "audio_dir = Path('../notebooks/tts_outputs/audio')\n",
    "text_dir = Path('../notebooks/tts_outputs/text')\n",
    "\n",
    "# Load Whisper model (base is fast, small is more accurate)\n",
    "model = whisper.load_model('base')\n",
    "\n",
    "def merge_into_sentences(segments: list[dict]) -> list[dict]:\n",
    "    \"\"\"Merge Whisper segments into full sentences (split on . ! ? and equivalents).\"\"\"\n",
    "    sentences, buf_text, buf_start, buf_end = [], [], None, 0\n",
    "    for seg in segments:\n",
    "        text = seg['text'].strip()\n",
    "        if not text:\n",
    "            continue\n",
    "        if buf_start is None:\n",
    "            buf_start = seg['start']\n",
    "        buf_text.append(text)\n",
    "        buf_end = seg['end']\n",
    "        if text[-1] in '.!?\\u3002\\uff1f\\uff01':\n",
    "            sentences.append({'text': ' '.join(buf_text), 'start': round(buf_start, 2), 'end': round(buf_end, 2)})\n",
    "            buf_text, buf_start = [], None\n",
    "    if buf_text:\n",
    "        sentences.append({'text': ' '.join(buf_text), 'start': round(buf_start, 2), 'end': round(buf_end, 2)})\n",
    "    return sentences\n",
    "\n",
    "def extract_and_merge(audio_path: str, language: str) -> list[dict]:\n",
    "    \"\"\"Run Whisper on audio, merge segments into full sentences.\"\"\"\n",
    "    result = model.transcribe(audio_path, language=language, word_timestamps=True, verbose=False)\n",
    "    segments = [{'text': s['text'].strip(), 'start': round(s['start'], 2), 'end': round(s['end'], 2)} for s in result['segments']]\n",
    "    return merge_into_sentences(segments)\n",
    "\n",
    "# --- EN ---\n",
    "en_audio = audio_dir / f'chirp3-en-pro-friendly-{today_str}.wav'\n",
    "if en_audio.exists():\n",
    "    print(f'Processing EN: {en_audio.name}...')\n",
    "    en_sentences = extract_and_merge(str(en_audio), language='en')\n",
    "    en_out = text_dir / f'sentences-en-{today_str}.json'\n",
    "    en_out.write_text(json.dumps(en_sentences, indent=2, ensure_ascii=False))\n",
    "    print(f'  -> {len(en_sentences)} sentences, saved to {en_out.name}')\n",
    "    for s in en_sentences[:3]:\n",
    "        print(f'  [{s[\"start\"]:6.1f}s - {s[\"end\"]:6.1f}s] {s[\"text\"][:80]}')\n",
    "else:\n",
    "    print(f'EN audio not found: {en_audio}')\n",
    "\n",
    "# --- KO ---\n",
    "ko_audio = audio_dir / f'gemini-tts-ko-kore-{today_str}.wav'\n",
    "if ko_audio.exists():\n",
    "    print(f'\\nProcessing KO: {ko_audio.name}...')\n",
    "    ko_sentences = extract_and_merge(str(ko_audio), language='ko')\n",
    "    ko_out = text_dir / f'sentences-ko-{today_str}.json'\n",
    "    ko_out.write_text(json.dumps(ko_sentences, indent=2, ensure_ascii=False))\n",
    "    print(f'  -> {len(ko_sentences)} sentences, saved to {ko_out.name}')\n",
    "    for s in ko_sentences[:3]:\n",
    "        print(f'  [{s[\"start\"]:6.1f}s - {s[\"end\"]:6.1f}s] {s[\"text\"][:80]}')\n",
    "else:\n",
    "    print(f'KO audio not found: {ko_audio}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN saved: da6d31d0-9c2e-47a9-9e1b-5bc12dc598aa (9,075 chars)\n",
      "KO saved: 0b8485d2-690f-427a-9ed7-e9f1cb897fef (5,872 chars)\n",
      "Linked 40 articles to each briefing\n"
     ]
    }
   ],
   "source": [
    "# Save EN + KO briefings to Supabase\n",
    "\n",
    "def save_briefing(briefing_text, category, model_name):\n",
    "    \"\"\"Upsert a briefing row and link articles.\"\"\"\n",
    "    record = {\n",
    "        'date': str(today),\n",
    "        'category': category,\n",
    "        'briefing_text': briefing_text,\n",
    "        'item_count': len(articles),\n",
    "        'model': model_name,\n",
    "    }\n",
    "    result = sb.table('wsj_briefings').upsert(\n",
    "        record, on_conflict='date,category'\n",
    "    ).execute()\n",
    "    bid = result.data[0]['id']\n",
    "\n",
    "    junction = [{'briefing_id': bid, 'wsj_item_id': a['id']} for a in articles]\n",
    "    for i in range(0, len(junction), 100):\n",
    "        sb.table('wsj_briefing_items').upsert(\n",
    "            junction[i:i+100], on_conflict='briefing_id,wsj_item_id'\n",
    "        ).execute()\n",
    "    return bid\n",
    "\n",
    "# EN briefing (from cell-18)\n",
    "en_id = save_briefing(briefing_pro, 'EN', 'gemini-2.5-pro')\n",
    "print(f'EN saved: {en_id} ({len(briefing_pro):,} chars)')\n",
    "\n",
    "# KO briefing (from cell-21)\n",
    "ko_id = save_briefing(briefing_ko, 'KO', 'gemini-2.5-pro')\n",
    "print(f'KO saved: {ko_id} ({len(briefing_ko):,} chars)')\n",
    "\n",
    "print(f'Linked {len(articles)} articles to each briefing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark all briefing articles as briefed in wsj_items\n",
    "# Prevents these articles from appearing in future briefings\n",
    "from datetime import datetime\n",
    "\n",
    "ids = [a['id'] for a in articles]\n",
    "for i in range(0, len(ids), 100):\n",
    "    batch = ids[i:i+100]\n",
    "    sb.table('wsj_items').update(\n",
    "        {'briefed': True, 'briefed_at': datetime.now().isoformat()}\n",
    "    ).in_('id', batch).execute()\n",
    "print(f'Marked {len(ids)} articles as briefed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved briefing: 6d02a403-60ae-4861-b5ef-52393d5d80bd\n",
      "Linked 40 articles to briefing\n"
     ]
    }
   ],
   "source": [
    "# Save briefing to Supabase\n",
    "briefing_record = {\n",
    "    'date': str(today),\n",
    "    'category': 'ALL',\n",
    "    'briefing_text': briefing_text,\n",
    "    'item_count': len(articles),\n",
    "    'model': 'gemini-2.5-flash',\n",
    "}\n",
    "\n",
    "result = sb.table('wsj_briefings').upsert(\n",
    "    briefing_record, on_conflict='date,category'\n",
    ").execute()\n",
    "\n",
    "briefing_id = result.data[0]['id']\n",
    "print(f'Saved briefing: {briefing_id}')\n",
    "\n",
    "junction_records = [{'briefing_id': briefing_id, 'wsj_item_id': a['id']} for a in articles]\n",
    "for i in range(0, len(junction_records), 100):\n",
    "    batch = junction_records[i:i+100]\n",
    "    sb.table('wsj_briefing_items').upsert(batch, on_conflict='briefing_id,wsj_item_id').execute()\n",
    "\n",
    "print(f'Linked {len(junction_records)} articles to briefing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- V1: Formal/premium broadcast tone ---\n",
    "BRIEFING_SYSTEM_FORMAL = \"\"\"You are the host-writer of a premium daily financial news audio briefing. You will receive ~80–100 news items; each has a title and description, and ~50% include a short summary plus extracted entities and key numbers. Produce one continuous, broadcast-ready script optimized for text-to-speech.\n",
    "\n",
    "Constraints:\n",
    "1,800–2,000 words (approximately 12–13 minutes at ~150 wpm).\n",
    "Output strictly plain text. No markdown, no bullet points, no numbered lists, and no section headers or labels (avoid \"Markets:\", \"Tech:\", etc.).\n",
    "Open with a warm greeting and today's date (use the date provided with the input). Close with a brief sign-off.\n",
    "\n",
    "Editorial rules:\n",
    "Don't read headlines one by one. Deduplicate immediately: merge overlapping coverage of the same event into one narrative using the richest available details.\n",
    "Prioritize stories with specific figures, named entities, tickers, timing, and measurable market moves. Use those details naturally.\n",
    "Allocate depth: spend ~60–70% of the script on the top 8–12 highest-impact narratives; cover the rest as brief contextual mentions without turning into a list.\n",
    "Mixed-quality handling: for rich-metadata items, include concrete specifics (earnings, guidance, deal values, macro prints). For title/description-only items, keep it to 1–2 cautious sentences and do not invent details.\n",
    "Entities/Numbers are extracted hints—only mention them when they are clearly supported by the description/summary and relevant to why the story matters.\n",
    "If sources conflict or details are uncertain, avoid false precision; use cautious language (e.g., \"reports vary\") and stick to the most supported facts.\n",
    "Use smooth transitions that connect cause and effect across themes (rates → tech multiples, oil → inflation, regulation → sector winners/losers). After major arcs, add a short \"what to watch next\" only if supported by the provided items.\n",
    "At the end, briefly note how many articles were covered out of the total provided (e.g., \"We covered X of today's Y stories\").\"\"\"\n",
    "\n",
    "\n",
    "# --- V3: Balanced — conversational but fact-first ---\n",
    "BRIEFING_SYSTEM_V3 = \"\"\"You are the host-writer of a daily financial news audio briefing optimized for text-to-speech. You will receive ~70–100 news items. Each item includes a title and description; about half include a short summary plus extracted entities and key numbers.\n",
    "\n",
    "Goal: Produce ONE continuous, broadcast-ready script that sounds conversational but remains fact-first and premium.\n",
    "\n",
    "Hard constraints:\n",
    "- 1,800–2,000 words total.\n",
    "- Output strictly plain text.\n",
    "- No markdown, no bullet points, no numbered lists, no section headers or labels (avoid \"Markets:\", \"Tech:\", etc.).\n",
    "- Open with a warm greeting and today's date (use the date provided in the input).\n",
    "- Close with a brief sign-off.\n",
    "- Paragraph breaks are allowed, but do not format as a list.\n",
    "\n",
    "Editorial rules (highest priority):\n",
    "1) Do NOT read headlines one by one. Immediately deduplicate: merge overlapping coverage of the same underlying event into a single narrative using the richest available details.\n",
    "2) Allocation: spend ~60–70% of the script on the top 8–12 highest-impact narratives. Cover the rest as brief contextual mentions without turning into a list.\n",
    "3) Prioritize items with specific figures, named entities, tickers, timing, and measurable market moves, but ONLY mention numbers/entities that are clearly supported by the provided description/summary.\n",
    "4) Mixed-quality handling:\n",
    "   - Rich-metadata items: include concrete specifics (earnings, guidance, deal values, macro prints) when present.\n",
    "   - Title/description-only items: limit to 1–2 cautious sentences; do not invent details.\n",
    "5) Conflicts/uncertainty: avoid false precision. If sources conflict, say so briefly (\"Reports are mixed…\") and stick to the most supported facts.\n",
    "\n",
    "Style rules (second priority, for listenability):\n",
    "- Write like you speak: mostly short punchy sentences, with occasional longer sentences when you need to explain.\n",
    "- Use smooth cause-and-effect transitions across themes (rates → multiples, oil → inflation, regulation → sector moves).\n",
    "- You may use rhetorical questions sparingly (max 3–6 times total) to pull listeners in, but never as filler.\n",
    "- Light reactions are allowed only when grounded in facts (e.g., surprising guidance, outsized move), and should not become opinionated.\n",
    "- Never be flippant about serious topics (layoffs, conflict, disasters).\n",
    "\n",
    "End requirement:\n",
    "- End by stating how many articles you covered out of the total provided (e.g., \"We covered X of today's Y stories.\").\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Usage & Cost Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all LLM usage — thinking budget utilization & cost\n",
    "COST_PER_1M = {\n",
    "    'pro-input': 1.25, 'pro-output': 10.0, 'pro-thinking': 3.75,\n",
    "    'flash-input': 0.15, 'flash-output': 0.60,\n",
    "}\n",
    "\n",
    "all_usage = [u for u in [curation_usage, en_usage, ko_usage] if u is not None]\n",
    "\n",
    "print('=' * 70)\n",
    "print('THINKING BUDGET UTILIZATION')\n",
    "print('-' * 70)\n",
    "print(f'{\"Step\":<16} {\"Model\":<28} {\"Budget\":>8} {\"Used\":>8} {\"Util%\":>6}')\n",
    "print('-' * 70)\n",
    "\n",
    "total_thinking_budget = 0\n",
    "total_thinking_used = 0\n",
    "\n",
    "for u in all_usage:\n",
    "    budget = u['thinking_budget']\n",
    "    used = u['thinking_used']\n",
    "    pct = used / budget * 100 if budget > 0 else 0\n",
    "    total_thinking_budget += budget\n",
    "    total_thinking_used += used\n",
    "    print(f'{u[\"step\"]:<16} {u[\"model\"]:<28} {budget:>8,} {used:>8,} {pct:>5.0f}%')\n",
    "\n",
    "total_pct = total_thinking_used / total_thinking_budget * 100 if total_thinking_budget else 0\n",
    "print('-' * 70)\n",
    "print(f'{\"TOTAL\":<16} {\"\":<28} {total_thinking_budget:>8,} {total_thinking_used:>8,} {total_pct:>5.0f}%')\n",
    "\n",
    "print()\n",
    "print('=' * 70)\n",
    "print('FULL TOKEN BREAKDOWN')\n",
    "print('-' * 70)\n",
    "print(f'{\"Step\":<16} {\"Input\":>10} {\"Output\":>10} {\"Thinking\":>10} {\"Time\":>8}')\n",
    "print('-' * 70)\n",
    "\n",
    "total_in = total_out = total_think = total_time = 0\n",
    "for u in all_usage:\n",
    "    print(f'{u[\"step\"]:<16} {u[\"input_tokens\"]:>10,} {u[\"output_tokens\"]:>10,} {u[\"thinking_used\"]:>10,} {u[\"elapsed\"]:>7.1f}s')\n",
    "    total_in += u['input_tokens']\n",
    "    total_out += u['output_tokens']\n",
    "    total_think += u['thinking_used']\n",
    "    total_time += u['elapsed']\n",
    "\n",
    "print('-' * 70)\n",
    "print(f'{\"TOTAL\":<16} {total_in:>10,} {total_out:>10,} {total_think:>10,} {total_time:>7.1f}s')\n",
    "\n",
    "# Cost estimate\n",
    "cost = 0\n",
    "for u in all_usage:\n",
    "    is_pro = 'pro' in (u['model'] or '')\n",
    "    prefix = 'pro' if is_pro else 'flash'\n",
    "    cost += u['input_tokens'] / 1e6 * COST_PER_1M[f'{prefix}-input']\n",
    "    cost += u['output_tokens'] / 1e6 * COST_PER_1M[f'{prefix}-output']\n",
    "    if is_pro and u['thinking_used']:\n",
    "        cost += u['thinking_used'] / 1e6 * COST_PER_1M['pro-thinking']\n",
    "\n",
    "thinking_cost = total_think / 1e6 * COST_PER_1M['pro-thinking']\n",
    "print(f'\\n--- Cost Estimate ---')\n",
    "print(f'Total LLM cost:     ${cost:.4f}')\n",
    "if cost > 0:\n",
    "    print(f'  Thinking portion: ${thinking_cost:.4f} ({thinking_cost/cost*100:.0f}% of total)')\n",
    "    print(f'\\nTip: If thinking utilization is consistently < 50%, consider lowering the budget to save ~${thinking_cost/2:.4f}/run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- think=0 ---\n",
      "  [DEBUG] usage_metadata type: <class 'google.genai.types.GenerateContentResponseUsageMetadata'>\n",
      "  [DEBUG] usage_metadata: cache_tokens_details=None cached_content_token_count=None candidates_token_count=57 candidates_tokens_details=None prompt_token_count=2454 prompt_tokens_details=[ModalityTokenCount(\n",
      "  modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "  token_count=2454\n",
      ")] thoughts_token_count=3955 tool_use_prompt_token_count=None tool_use_prompt_tokens_details=None total_token_count=6466 traffic_type=None\n",
      "  [DEBUG] dir: ['cache_tokens_details', 'cached_content_token_count', 'candidates_token_count', 'candidates_tokens_details', 'construct', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'prompt_token_count', 'prompt_tokens_details', 'schema', 'schema_json', 'thoughts_token_count', 'to_json_dict', 'tool_use_prompt_token_count', 'tool_use_prompt_tokens_details', 'total_token_count', 'traffic_type', 'update_forward_refs', 'validate']\n",
      "  Articles: [2, 3, 9, 11, 18, 19, 20, 23, 25, 30, 31, 32, 35, 38, 40]\n",
      "  Think: off\n",
      "  Cost: $0.0185 | Time: 32.5s\n",
      "\n",
      "--- think=1024 ---\n",
      "  Articles: [2, 3, 9, 11, 14, 18, 19, 20, 23, 25, 30, 32, 35, 38, 40]\n",
      "  Think: 1,039/1,024\n",
      "  Cost: $0.0075 | Time: 9.3s\n",
      "\n",
      "--- think=2048 ---\n",
      "  Articles: [3, 9, 11, 14, 18, 19, 20, 23, 30, 31, 32, 35, 38, 40]\n",
      "  Think: 3,081/2,048\n",
      "  Cost: $0.0152 | Time: 25.3s\n",
      "\n",
      "--- think=4096 ---\n",
      "  Articles: [3, 9, 11, 12, 18, 19, 20, 23, 30, 31, 32, 33, 35, 38, 40]\n",
      "  Think: 3,047/4,096\n",
      "  Cost: $0.0151 | Time: 24.9s\n",
      "\n",
      "--- think=32768 ---\n",
      "  Articles: [3, 9, 11, 14, 18, 19, 20, 23, 25, 30, 31, 32, 35, 38, 40]\n",
      "  Think: 3,771/32,768\n",
      "  Cost: $0.0178 | Time: 29.2s\n",
      "\n",
      "\n",
      "================================================================================\n",
      "  Budget    #    Think      Cost    Time  Selected\n",
      "--------------------------------------------------------------------------------\n",
      "       0   15      off $0.0185   32.5s  [2, 3, 9, 11, 18, 19, 20, 23, 25, 30, 31, 32, 35, 38, 40]\n",
      "    1024   15    1,039 $0.0075    9.3s  [2, 3, 9, 11, 14, 18, 19, 20, 23, 25, 30, 32, 35, 38, 40]\n",
      "    2048   14    3,081 $0.0152   25.3s  [3, 9, 11, 14, 18, 19, 20, 23, 30, 31, 32, 35, 38, 40]\n",
      "    4096   15    3,047 $0.0151   24.9s  [3, 9, 11, 12, 18, 19, 20, 23, 30, 31, 32, 33, 35, 38, 40]\n",
      "   32768   15    3,771 $0.0178   29.2s  [3, 9, 11, 14, 18, 19, 20, 23, 25, 30, 31, 32, 35, 38, 40]\n",
      "\n",
      "Overlap vs think=32768:\n",
      "  think=    0: 14/15 (93%)  +[2]  -[14]\n",
      "  think= 1024: 14/15 (93%)  +[2]  -[31]\n",
      "  think= 2048: 14/15 (93%)  -[25]\n",
      "  think= 4096: 13/15 (87%)  +[12, 33]  -[14, 25]\n",
      "  think=32768: 15/15 (100%)\n",
      "\n",
      "Saved: curation-ab-2026-02-15.json\n"
     ]
    }
   ],
   "source": [
    "# Curation Thinking Budget A/B Test\n",
    "# Requires: cell-1 (imports), cell-3 (articles), cell-6 (crawl+llm), cell-9 (curation_input, try_curation)\n",
    "\n",
    "BUDGETS = [0, 1024, 2048, 4096, 32768]\n",
    "results = {}\n",
    "\n",
    "for budget in BUDGETS:\n",
    "    print(f'\\n--- think={budget} ---')\n",
    "    if budget == 0:\n",
    "        cfg = types.GenerateContentConfig(max_output_tokens=4096, temperature=0.1)\n",
    "    else:\n",
    "        cfg = types.GenerateContentConfig(\n",
    "            max_output_tokens=4096, temperature=0.1,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=budget),\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "    raw, resp = try_curation('gemini-2.5-pro', cfg, f'think={budget}')\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    if not raw:\n",
    "        print('  FAILED'); continue\n",
    "\n",
    "    # Debug: print actual usage_metadata fields (first run only)\n",
    "    if not results:\n",
    "        print(f'  [DEBUG] usage_metadata type: {type(resp.usage_metadata)}')\n",
    "        print(f'  [DEBUG] usage_metadata: {resp.usage_metadata}')\n",
    "        print(f'  [DEBUG] dir: {[a for a in dir(resp.usage_metadata) if not a.startswith(\"_\")]}')\n",
    "\n",
    "    cleaned = re.sub(r'```json\\s*', '', raw.strip())\n",
    "    cleaned = re.sub(r'```\\s*', '', cleaned).strip()\n",
    "    m = re.search(r'\\[[\\d,\\s]+\\]', cleaned)\n",
    "    if not m:\n",
    "        print(f'  Parse error: {raw[:80]}'); continue\n",
    "\n",
    "    indices = sorted(json.loads(m.group()))\n",
    "    um = resp.usage_metadata\n",
    "    think_used = getattr(um, 'thinking_token_count', None) or getattr(um, 'thoughts_token_count', None) or 0\n",
    "    in_tok = um.prompt_token_count or 0\n",
    "    out_tok = um.candidates_token_count or 0\n",
    "    cost = in_tok/1e6*1.25 + out_tok/1e6*10.0 + think_used/1e6*3.75\n",
    "\n",
    "    results[budget] = {'indices': indices, 'think_used': think_used, 'in': in_tok, 'out': out_tok, 'cost': cost, 'time': elapsed}\n",
    "    print(f'  Articles: {indices}')\n",
    "    print(f'  Think: {think_used:,}/{budget:,}' if budget else '  Think: off')\n",
    "    print(f'  Cost: ${cost:.4f} | Time: {elapsed:.1f}s')\n",
    "    time.sleep(2)\n",
    "\n",
    "# --- Summary ---\n",
    "print(f'\\n\\n{\"=\"*80}')\n",
    "print(f'{\"Budget\":>8} {\"#\":>4} {\"Think\":>8} {\"Cost\":>9} {\"Time\":>7}  Selected')\n",
    "print(f'{\"-\"*80}')\n",
    "for b in BUDGETS:\n",
    "    r = results.get(b)\n",
    "    if not r: continue\n",
    "    t = f'{r[\"think_used\"]:,}' if b else 'off'\n",
    "    print(f'{b:>8} {len(r[\"indices\"]):>4} {t:>8} ${r[\"cost\"]:.4f} {r[\"time\"]:>6.1f}s  {r[\"indices\"]}')\n",
    "\n",
    "# --- Overlap ---\n",
    "if len(results) >= 2:\n",
    "    base_b = max(results.keys())\n",
    "    base_set = set(results[base_b]['indices'])\n",
    "    print(f'\\nOverlap vs think={base_b}:')\n",
    "    for b in BUDGETS:\n",
    "        r = results.get(b)\n",
    "        if not r: continue\n",
    "        cur = set(r['indices'])\n",
    "        overlap = cur & base_set\n",
    "        pct = len(overlap)/len(base_set)*100 if base_set else 0\n",
    "        diff = sorted(cur - base_set)\n",
    "        miss = sorted(base_set - cur)\n",
    "        print(f'  think={b:>5}: {len(overlap)}/{len(base_set)} ({pct:.0f}%)', end='')\n",
    "        if diff:\n",
    "            print(f'  +{diff}', end='')\n",
    "        if miss and b != base_b:\n",
    "            print(f'  -{miss}', end='')\n",
    "        print()\n",
    "\n",
    "# --- Save to file ---\n",
    "today_file = date.today().strftime('%Y-%m-%d')\n",
    "out_dir = Path('../notebooks/tts_outputs/text')\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_path = out_dir / f'curation-ab-{today_file}.json'\n",
    "\n",
    "save_data = {\n",
    "    'date': today_file,\n",
    "    'article_count': len(items.data),\n",
    "    'budgets_tested': BUDGETS,\n",
    "    'results': {\n",
    "        str(b): {\n",
    "            'indices': r['indices'],\n",
    "            'titles': [items.data[i-1]['title'] for i in r['indices'] if 1 <= i <= len(items.data)],\n",
    "            'think_used': r['think_used'],\n",
    "            'input_tokens': r['in'],\n",
    "            'output_tokens': r['out'],\n",
    "            'cost_usd': round(r['cost'], 6),\n",
    "            'elapsed_s': round(r['time'], 1),\n",
    "        } for b, r in results.items()\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(str(out_path), 'w') as f:\n",
    "    json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
    "print(f'\\nSaved: {out_path.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Briefing Thinking Budget A/B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=off)...\n",
      "  Words: 1788 | Chars: 10,853\n",
      "  Think: off\n",
      "  Cost: $0.0686 | Time: 51.5s\n",
      "  Saved: briefing-en-think0-2026-02-15.txt\n",
      "  Preview: Good morning, and welcome to the show. It’s Thursday, February 15th, 2026. Thanks for starting your day with us. We’ve got a lot to get through today, from the latest inflation numbers that are giving...\n",
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=1024)...\n",
      "  Words: 1675 | Chars: 10,212\n",
      "  Think: 763/1,024\n",
      "  Cost: $0.0606 | Time: 31.8s\n",
      "  Saved: briefing-en-think1024-2026-02-15.txt\n",
      "  Preview: Good morning, and welcome to the show. It is Sunday, February 15th, 2026.\n",
      "\n",
      "So glad you could tune in. Today, we've got a lot to unpack, starting with the latest inflation numbers and what they mean fo...\n",
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=2048)...\n",
      "  Words: 1653 | Chars: 10,135\n",
      "  Think: 1,589/2,048\n",
      "  Cost: $0.0631 | Time: 40.6s\n",
      "  Saved: briefing-en-think2048-2026-02-15.txt\n",
      "  Preview: Good morning, it's February 15th, 2026. Great to have you with me.\n",
      "\n",
      "Today, we're going to get into the latest inflation numbers and what they mean for that soft landing everyone keeps talking about. T...\n",
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=4096)...\n",
      "  Words: 1705 | Chars: 10,375\n",
      "  Think: 2,286/4,096\n",
      "  Cost: $0.0663 | Time: 45.8s\n",
      "  Saved: briefing-en-think4096-2026-02-15.txt\n",
      "  Preview: Good morning, and welcome to the show. It's February 15th, 2026. We’ve got a lot to get to today. We're going to break down the latest inflation numbers and what they mean for that soft landing everyo...\n",
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=8192)...\n",
      "  Words: 1611 | Chars: 9,855\n",
      "  Think: 2,598/8,192\n",
      "  Cost: $0.0661 | Time: 48.5s\n",
      "  Saved: briefing-en-think8192-2026-02-15.txt\n",
      "  Preview: Good morning, and welcome to the show. It’s Friday, February 15th, 2026.\n",
      "\n",
      "Glad you could join me. Today we’ve got a lot to unpack, starting with the latest inflation numbers that have everyone talking...\n",
      "\n",
      "============================================================\n",
      "Generating EN briefing (think=32768)...\n",
      "  Words: 1751 | Chars: 10,623\n",
      "  Think: 2,599/32,768\n",
      "  Cost: $0.0683 | Time: 52.5s\n",
      "  Saved: briefing-en-think32768-2026-02-15.txt\n",
      "  Preview: Good morning, and welcome to the podcast. It’s February 15, 2026. Today we’ve got the latest inflation numbers that have everyone talking about a soft landing, a couple of truly wild AI stories includ...\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "BRIEFING THINKING BUDGET A/B RESULTS\n",
      "==========================================================================================\n",
      "  Budget   Words   Chars    Think      Cost    Time  Preview\n",
      "------------------------------------------------------------------------------------------\n",
      "       0    1788  10,853      off $0.0686   51.5s  Good morning, and welcome to the show. It’s Thursday, Februa...\n",
      "    1024    1675  10,212      763 $0.0606   31.8s  Good morning, and welcome to the show. It is Sunday, Februar...\n",
      "    2048    1653  10,135    1,589 $0.0631   40.6s  Good morning, it's February 15th, 2026. Great to have you wi...\n",
      "    4096    1705  10,375    2,286 $0.0663   45.8s  Good morning, and welcome to the show. It's February 15th, 2...\n",
      "    8192    1611   9,855    2,598 $0.0661   48.5s  Good morning, and welcome to the show. It’s Friday, February...\n",
      "   32768    1751  10,623    2,599 $0.0683   52.5s  Good morning, and welcome to the podcast. It’s February 15, ...\n",
      "\n",
      "--- Word Count vs Target (1800-2000) ---\n",
      "  think=    0:  1788 words ↓ SHORT █████████████████\n",
      "  think= 1024:  1675 words ↓ SHORT ████████████████\n",
      "  think= 2048:  1653 words ↓ SHORT ████████████████\n",
      "  think= 4096:  1705 words ↓ SHORT █████████████████\n",
      "  think= 8192:  1611 words ↓ SHORT ████████████████\n",
      "  think=32768:  1751 words ↓ SHORT █████████████████\n",
      "\n",
      "--- Cost Range ---\n",
      "  Cheapest: $0.0606 (think=1024)\n",
      "  Most expensive: $0.0686 (think=0)\n",
      "  Savings (min vs max): $0.0081 (12%)\n",
      "\n",
      "Saved: briefing-ab-2026-02-15.json\n",
      "\n",
      "READ THE FILES to compare quality — word count and cost alone don't tell the full story.\n"
     ]
    }
   ],
   "source": [
    "# Briefing Thinking Budget A/B Test\n",
    "# Requires: cell-14 (BRIEFING_SYSTEM, articles_text), cell-1 (gemini_client)\n",
    "# Tests EN briefing with different thinking budgets to find optimal quality/cost tradeoff\n",
    "# Similar methodology to curation A/B test (cell-28)\n",
    "\n",
    "BUDGETS = [0, 1024, 2048, 4096, 8192, 32768]\n",
    "results = {}\n",
    "today_file = date.today().strftime('%Y-%m-%d')\n",
    "text_dir = Path('../notebooks/tts_outputs/text')\n",
    "text_dir.mkdir(exist_ok=True)\n",
    "\n",
    "full = BRIEFING_SYSTEM + \"\\n\\n\" + articles_text\n",
    "\n",
    "for budget in BUDGETS:\n",
    "    label = f'think={budget}' if budget else 'think=off'\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Generating EN briefing ({label})...')\n",
    "\n",
    "    if budget == 0:\n",
    "        cfg = types.GenerateContentConfig(\n",
    "            max_output_tokens=8192, temperature=0.6,\n",
    "        )\n",
    "    else:\n",
    "        cfg = types.GenerateContentConfig(\n",
    "            max_output_tokens=8192, temperature=0.6,\n",
    "            thinking_config=types.ThinkingConfig(thinking_budget=budget),\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        resp = gemini_client.models.generate_content(\n",
    "            model='gemini-2.5-pro', contents=full, config=cfg,\n",
    "        )\n",
    "        text = resp.text\n",
    "    except Exception as e:\n",
    "        print(f'  FAILED: {e.__class__.__name__}: {e}')\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    um = resp.usage_metadata\n",
    "    think_used = getattr(um, 'thoughts_token_count', None) or getattr(um, 'thinking_token_count', None) or 0\n",
    "    in_tok = um.prompt_token_count or 0\n",
    "    out_tok = um.candidates_token_count or 0\n",
    "    cost = in_tok/1e6*1.25 + out_tok/1e6*10.0 + think_used/1e6*3.75\n",
    "\n",
    "    words = len(text.split())\n",
    "    chars = len(text)\n",
    "\n",
    "    # Save each variant\n",
    "    txt_path = text_dir / f'briefing-en-think{budget}-{today_file}.txt'\n",
    "    with open(str(txt_path), 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "    results[budget] = {\n",
    "        'text': text,\n",
    "        'words': words,\n",
    "        'chars': chars,\n",
    "        'think_used': think_used,\n",
    "        'in': in_tok,\n",
    "        'out': out_tok,\n",
    "        'cost': cost,\n",
    "        'time': elapsed,\n",
    "        'model': resp.model_version,\n",
    "        'file': txt_path.name,\n",
    "    }\n",
    "\n",
    "    print(f'  Words: {words} | Chars: {chars:,}')\n",
    "    print(f'  Think: {think_used:,}/{budget:,}' if budget else '  Think: off')\n",
    "    print(f'  Cost: ${cost:.4f} | Time: {elapsed:.1f}s')\n",
    "    print(f'  Saved: {txt_path.name}')\n",
    "    print(f'  Preview: {text[:200]}...')\n",
    "    time.sleep(3)  # rate limit buffer\n",
    "\n",
    "# --- Summary Table ---\n",
    "print(f'\\n\\n{\"=\"*90}')\n",
    "print(f'BRIEFING THINKING BUDGET A/B RESULTS')\n",
    "print(f'{\"=\"*90}')\n",
    "print(f'{\"Budget\":>8} {\"Words\":>7} {\"Chars\":>7} {\"Think\":>8} {\"Cost\":>9} {\"Time\":>7}  Preview')\n",
    "print(f'{\"-\"*90}')\n",
    "for b in BUDGETS:\n",
    "    r = results.get(b)\n",
    "    if not r: continue\n",
    "    t = f'{r[\"think_used\"]:,}' if b else 'off'\n",
    "    preview = r['text'][:60].replace('\\n', ' ')\n",
    "    print(f'{b:>8} {r[\"words\"]:>7} {r[\"chars\"]:>7,} {t:>8} ${r[\"cost\"]:.4f} {r[\"time\"]:>6.1f}s  {preview}...')\n",
    "\n",
    "# --- Word count target check ---\n",
    "print(f'\\n--- Word Count vs Target (1800-2000) ---')\n",
    "for b in BUDGETS:\n",
    "    r = results.get(b)\n",
    "    if not r: continue\n",
    "    w = r['words']\n",
    "    status = '✓ IN RANGE' if 1800 <= w <= 2000 else ('↓ SHORT' if w < 1800 else '↑ LONG')\n",
    "    bar = '█' * min(w // 100, 25)\n",
    "    print(f'  think={b:>5}: {w:>5} words {status} {bar}')\n",
    "\n",
    "# --- Cost comparison ---\n",
    "if results:\n",
    "    max_cost = max(r['cost'] for r in results.values())\n",
    "    min_cost = min(r['cost'] for r in results.values())\n",
    "    print(f'\\n--- Cost Range ---')\n",
    "    print(f'  Cheapest: ${min_cost:.4f} (think={min(b for b, r in results.items() if r[\"cost\"] == min_cost)})')\n",
    "    print(f'  Most expensive: ${max_cost:.4f} (think={max(b for b, r in results.items() if r[\"cost\"] == max_cost)})')\n",
    "    print(f'  Savings (min vs max): ${max_cost - min_cost:.4f} ({(max_cost - min_cost)/max_cost*100:.0f}%)')\n",
    "\n",
    "# --- Save full results to JSON ---\n",
    "out_path = text_dir / f'briefing-ab-{today_file}.json'\n",
    "save_data = {\n",
    "    'date': today_file,\n",
    "    'test': 'briefing_thinking_budget',\n",
    "    'model': 'gemini-2.5-pro',\n",
    "    'temperature': 0.6,\n",
    "    'prompt': 'BRIEFING_SYSTEM_FRIENDLY (EN)',\n",
    "    'article_count': len(articles),\n",
    "    'budgets_tested': BUDGETS,\n",
    "    'results': {\n",
    "        str(b): {\n",
    "            'words': r['words'],\n",
    "            'chars': r['chars'],\n",
    "            'think_used': r['think_used'],\n",
    "            'input_tokens': r['in'],\n",
    "            'output_tokens': r['out'],\n",
    "            'cost_usd': round(r['cost'], 6),\n",
    "            'elapsed_s': round(r['time'], 1),\n",
    "            'preview': r['text'][:300],\n",
    "            'file': r['file'],\n",
    "        } for b, r in results.items()\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(str(out_path), 'w') as f:\n",
    "    json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
    "print(f'\\nSaved: {out_path.name}')\n",
    "print(f'\\nREAD THE FILES to compare quality — word count and cost alone don\\'t tell the full story.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "araverus (.venv)",
   "language": "python",
   "name": "araverus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
